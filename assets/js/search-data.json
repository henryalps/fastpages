{
  
    
        "post0": {
            "title": "Pytorch一小时入门",
            "content": "更新记录： . 20/05/31(I) 完成前两节（30min）的内容 . 学习了DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ，将过程记录在此处。 . TK: add title . 1.理解PyTorch的Tensor库 | 2.Autograd自动求导的应用 | 3.构建神经网络 | 4.一个实际的例子 | . &#29702;&#35299;PyTorch&#30340;Tensor&#24211; . Tesnsor&#30340;&#23450;&#20041; . Tensors和NumPy的ndarray结构很像，区别是Tensor可以用于GPU计算。 . from __future__ import print_function import torch # check the GPU support dir(torch.cuda) . [&#39;BFloat16Storage&#39;, &#39;BFloat16Tensor&#39;, &#39;BoolStorage&#39;, &#39;BoolTensor&#39;, &#39;ByteStorage&#39;, &#39;ByteTensor&#39;, &#39;CharStorage&#39;, &#39;CharTensor&#39;, &#39;CudaError&#39;, &#39;DeferredCudaCallError&#39;, &#39;DoubleStorage&#39;, &#39;DoubleTensor&#39;, &#39;Event&#39;, &#39;FloatStorage&#39;, &#39;FloatTensor&#39;, &#39;HalfStorage&#39;, &#39;HalfTensor&#39;, &#39;IntStorage&#39;, &#39;IntTensor&#39;, &#39;LongStorage&#39;, &#39;LongTensor&#39;, &#39;PIPE&#39;, &#39;Popen&#39;, &#39;ShortStorage&#39;, &#39;ShortTensor&#39;, &#39;Stream&#39;, &#39;_CudaBase&#39;, &#39;_StorageBase&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;_after_fork&#39;, &#39;_check_capability&#39;, &#39;_check_driver&#39;, &#39;_cudart&#39;, &#39;_dummy_type&#39;, &#39;_free_mutex&#39;, &#39;_get_device_index&#39;, &#39;_host_allocator&#39;, &#39;_in_bad_fork&#39;, &#39;_initialized&#39;, &#39;_lazy_call&#39;, &#39;_lazy_init&#39;, &#39;_lazy_new&#39;, &#39;_load_cudart&#39;, &#39;_original_pid&#39;, &#39;_queued_calls&#39;, &#39;_register_after_fork&#39;, &#39;_sleep&#39;, &#39;_utils&#39;, &#39;check_error&#39;, &#39;comm&#39;, &#39;contextlib&#39;, &#39;ctypes&#39;, &#39;cudaStatus&#39;, &#39;cudart&#39;, &#39;current_blas_handle&#39;, &#39;current_device&#39;, &#39;current_stream&#39;, &#39;default_stream&#39;, &#39;device&#39;, &#39;device_count&#39;, &#39;device_of&#39;, &#39;empty_cache&#39;, &#39;find_cuda_windows_lib&#39;, &#39;get_device_capability&#39;, &#39;get_device_name&#39;, &#39;get_device_properties&#39;, &#39;get_rng_state&#39;, &#39;get_rng_state_all&#39;, &#39;init&#39;, &#39;initial_seed&#39;, &#39;ipc_collect&#39;, &#39;is_available&#39;, &#39;manual_seed&#39;, &#39;manual_seed_all&#39;, &#39;max_memory_allocated&#39;, &#39;max_memory_cached&#39;, &#39;memory_allocated&#39;, &#39;memory_cached&#39;, &#39;nccl&#39;, &#39;nvtx&#39;, &#39;os&#39;, &#39;platform&#39;, &#39;profiler&#39;, &#39;raise_from&#39;, &#39;random&#39;, &#39;reset_max_memory_allocated&#39;, &#39;reset_max_memory_cached&#39;, &#39;seed&#39;, &#39;seed_all&#39;, &#39;set_device&#39;, &#39;set_rng_state&#39;, &#39;set_rng_state_all&#39;, &#39;sparse&#39;, &#39;stream&#39;, &#39;streams&#39;, &#39;synchronize&#39;, &#39;sys&#39;, &#39;torch&#39;, &#39;traceback&#39;, &#39;warnings&#39;] . assert(torch.cuda.is_available()) . 创建一个5x3张量，不初始化 . x=torch.empty(5,3) print(x) . tensor([[ 8.4078e-45, 0.0000e+00, 2.6136e-28], [ 5.5772e-43, -1.3120e-30, 4.5915e-41], [ 0.0000e+00, 0.0000e+00, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 0.0000e+00], [-1.3120e-30, 4.5915e-41, 0.0000e+00]]) . ???这里的表现和页面不一样，预期应该是全0才对 . 创建一个随机初始化张量 . x=torch.rand(5,3) print(x) . tensor([[0.3783, 0.4491, 0.0897], [0.2913, 0.1618, 0.6047], [0.2112, 0.3987, 0.1202], [0.8236, 0.2970, 0.4896], [0.4792, 0.2471, 0.6751]]) . 创建一个填0的long型张量 . x=torch.zeros(5,3,dtype=torch.long) print(x) . tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) . 从数据中直接创建一个张量 . x=torch.tensor([5.5,3.0]) print(x) . tensor([5.5000, 3.0000]) . 根据一个已有张量创建张量 . # 创建一个类型变为double型的全1张量 x=x.new_ones(5,3,dtype=torch.double) print(x) x=torch.randn_like(x,dtype=torch.float) print(x) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.4722, -0.4380, -1.0941], [ 0.6054, 0.6555, -1.1304], [-1.1721, 1.3889, 0.3657], [-1.6273, -0.0502, 0.8097], [ 1.3560, 0.1341, 1.6279]]) . torch.size实际是一个tuple . print(x.size()) print(x.size()[0]) . torch.Size([5, 3]) 5 . Tensor&#25805;&#20316; . 加法之两种符号类型 . # 类型1- 直接用加号 x = torch.ones(5,3) y = torch.zeros(5,3) print(x + y) # 类型2- 使用函数add print(torch.add(x,y)) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . ？？？为何要用两种符号表示呢 . 加法之指定结果tensor . result = torch.empty(5,3) torch.add(x,y,out=result) print(result) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . 加法之原位相加 . y.add_(x) print(y) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . 注意到所有原位运算都是在函数名后边加一个下划线 . 使用类似numpy的范围写法取tensor的部分值 . # 打印x的第一列 print(x[:,1]) # 打印x的第一行 print(x[1,:]) . tensor([1., 1., 1., 1., 1.]) tensor([1., 1., 1.]) . 改变tensor的维度 . x = torch.randn(4,4) y = x.view(16) # 只指定每行的元素数量，就可以计算出变换后的形状 z = x.view(-1, 2) print(x,y,z) . tensor([[ 1.7866, 1.8163, -0.4897, 0.6796], [-1.1594, 1.8653, -0.4756, -0.8084], [ 0.5253, 1.8867, 1.2337, -0.1705], [ 0.6688, 0.0531, -0.9582, -0.4612]]) tensor([ 1.7866, 1.8163, -0.4897, 0.6796, -1.1594, 1.8653, -0.4756, -0.8084, 0.5253, 1.8867, 1.2337, -0.1705, 0.6688, 0.0531, -0.9582, -0.4612]) tensor([[ 1.7866, 1.8163], [-0.4897, 0.6796], [-1.1594, 1.8653], [-0.4756, -0.8084], [ 0.5253, 1.8867], [ 1.2337, -0.1705], [ 0.6688, 0.0531], [-0.9582, -0.4612]]) . tensor的操作还有很多，此处实际没有完全列举 . Numpy&#26725;&#25509; - &#22312;tensor&#19982;numpy&#25968;&#32452;&#20043;&#38388;&#20114;&#30456;&#36716;&#25442; . numpy数组和tensor共享内存：这意味着对任何一个变量的改变都将同步到另一个上。 . 转化tensor为一个ndarray . a=torch.ones(5) b=a.numpy() print(a,b) . tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.] . 对tensor的改变将会反映到ndarray上 . a.add_(a) print(b) . [2. 2. 2. 2. 2.] . 对ndarray的改变将会反映到tensor上 . b+=1 print(a) . tensor([3., 3., 3., 3., 3.]) . 将ndarray转换为tensor . import numpy as np a = np.ones(5) #注意此处的变量命名 b = torch.from_numpy(a) np.add(a,1,out=a) print(a) print(b) . [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) . GPU&#19978;&#30340;tensor . 使用to()方法将tensor迁移到其它设备 . device = torch.device(&quot;cuda&quot;) y = torch.ones_like(x, device=device) x = x.to(device) z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.int)) . tensor([[ 2.7866, 2.8163, 0.5103, 1.6796], [-0.1594, 2.8653, 0.5244, 0.1916], [ 1.5253, 2.8867, 2.2337, 0.8295], [ 1.6688, 1.0531, 0.0418, 0.5388]], device=&#39;cuda:0&#39;) tensor([[2, 2, 0, 1], [0, 2, 0, 0], [1, 2, 2, 0], [1, 1, 0, 0]], dtype=torch.int32) . Autograd&#33258;&#21160;&#27714;&#23548;&#30340;&#24212;&#29992; . pytorch中神经网络的核心模块就是autograd包，我们简单地了解一下这个包，其后就可以开始训练我们的第一个神经网络了。 . autograd包可以对所有的tensor操作进行自动差分（？？？如何自定义运算符）。它是一个define-by-run的框架，也就是你的反向传播是由代码运行方式所决定的，每一个操作都会有不同。 . 我们用更简单的方式和例子进行解释。 . tensor . torch.Tensor是这个包的核心。如果你将其属性.requires_grad设为True，它将追踪其上的所有操作。当你完成计算后，可以调用.backward()方法以自动计算所有导数。这个tensor的导数将由.grad参数所体现。 . 为了结束对一个tensor求导的操作，你可以用.detach方法将它从计算历史中移除，以避免之后它又被继续求导。 . 为了避免对tensor求导占用内存，你可以将代码块用with torch.no_grad()包裹起来。这对模型评估尤其有用，因为其中可能存在设置了require_grad=True的参数，但我们却不需要求导数。 . Function类是另外一个非常常用的类。 . Tensor和Function共同作用以构建一个无环图，该图对完整的计算历史进行编码。每个tensor都有一个.grad_fn属性，其中保存了创建这个tensor的Function对象。（用户自己创建的tensor则没有这个属性） . 如果你想计算导数，你可以调用tensor的.backward()方法。如果tensor是一个标量（即包含单个元素），你不需要为backward()指定任何参数。但如果它有多于一个元素，则你必需为它指定gradient参数，其形状与该tensor对应。 . 创建一个tensor并设定require_grad为True以追踪其上的计算： . x = torch.ones(2,2,requires_grad=True) print(x) . tensor([[1., 1.], [1., 1.]], requires_grad=True) . tensor运算 . y = x + 2 print(y) . tensor([[3., 3.], [3., 3.]], grad_fn=&lt;AddBackward0&gt;) . 更多的tensor运算 . z = y * y * 3 out = z.mean() print(z, out) . tensor([[27., 27.], [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;) . .requires_grad_()可用于替换一个已有tensor的require_grad标志位。输入标志位默认为False。 . a = torch.randn(2,2) a=((a*3)/(a-1)) print(a.requires_grad) print(a.grad_fn) a.requires_grad_(True) print(a.requires_grad) print(a.grad_fn) b=(a*a).sum() print(b.grad_fn) . False None True None &lt;SumBackward0 object at 0x00000240968298D0&gt; . 进行反向传播。由于out是一个标量，所以无需传入参数 . out.backward() print(x.grad) . tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) . 如果我们将out定义为$o$,那么我们将有$o= frac{1}{4} sum_{i}3(x_i+2)^2$,此时$ frac{ partial o}{ partial x_i}= frac{3}{2}(x_i+2)$,因此$ frac{ partial o}{ partial x_i} mid_{x_i=1}=4.5$ . 数学上来说，如果你有一个因自变量都为向量的函数$ vec{y}=f( vec{x})$,那么$ vec{y}$对$ vec{x}$的导数为一个雅可比矩阵： . $J= left( begin{array}{ccc} frac{ partial y_{1}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{1}}{ partial x_{n}} vdots &amp; ddots &amp; vdots frac{ partial y_{m}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{n}} end{array} right)$ . 一般地，torch.autograd是一个用于计算向量-雅可比行列式乘积的工具。也就是说，给定任何向量$v=(v_1 v_2 ... v_m)^T$，如果$v$刚好是标量函数$l=g( vec{y})$的导数，也就是说$v= left( frac{ partial l}{ partial y_{1}} cdots frac{ partial l}{ partial y_{m}} right)^{T}$，那么根据链式法则有向量与雅克比行列式之积为 $J^{T} cdot v= left( begin{array}{ccc} frac{ partial y_{1}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{1}} vdots &amp; ddots &amp; vdots frac{ partial y_{1}}{ partial x_{n}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{n}} end{array} right) left( begin{array}{c} frac{ partial l}{ partial y_{1}} frac{ partial l}{ partial y_{m}} end{array} right)= left( begin{array}{c} frac{ partial l}{ partial x_{1}} frac{ partial l}{ partial x_{n}} end{array} right)$ . 向量与雅克比行列式之积的这种性质使得，将额外的导数引入输出不为常量的模型非常方便。 现在我们看一下向量-雅克比积的一个例子： . x = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm()&lt;1000: y=y*2 print(y) . tensor([-800.3267, 194.5804, 608.2095], grad_fn=&lt;MulBackward0&gt;) . 在这个例子中y不再是一个标量了。torch.autograd不能直接计算完整的雅克比行列式，但如果我们只想要向量-雅克比行列式之积的话，就简单将向量传入backward参数即可： . v = torch.tensor([0.1,1.0,0.0001], dtype=torch.float) y.backward(v) print(x.grad) . tensor([5.1200e+01, 5.1200e+02, 5.1200e-02]) . 关于上面这一段知乎链接讲的比较清楚，主要动机是不允许tensor对tensor求导，只允许scalar对tensor求导。 . 如果想对已经设置requires_grad=True的张量停止自动求导，有两种方式： . 1.使用with torch.no_grad()包裹 . 2.使用.detach()获取一个新的不需导数的张量 . print(x.requires_grad) print((x**2).requires_grad) with torch.no_grad(): print((x**2).requires_grad) print(x.requires_grad) y=x.detach() print(y.requires_grad) print(x.eq(y).all()) . True True False True False tensor(True) .",
            "url": "https://henryalps.github.io/fastpages/jupyter/pytorch/2020/05/30/Getting-Pytorch-one-hour.html",
            "relUrl": "/jupyter/pytorch/2020/05/30/Getting-Pytorch-one-hour.html",
            "date": " • May 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "create a new blog!",
            "content": "!pip install translation . ^C . from googletrans import Translator from datetime import datetime from functools import lru_cache title=&#39;自动生成Jupyter笔记本文件&#39; description=&#39;使用代码自动生成的Jupyter笔记本文件&#39; toc=&#39;true&#39; tags=&#39;,&#39;.join([&#39;jupyter&#39;]) branch=&#39;master&#39; badges=&#39;true&#39; comments=&#39;true&#39; date=datetime.today().strftime(&#39;%Y-%m-%d&#39;) @lru_cache(maxsize=10) def translate(text): return &#39;-&#39;.join(Translator().translate(text).text.split()) if len(title) &lt; 1: print(&#39;title not set!&#39;) exit() format_title = translate(title) print(format_title) import nbformat as nbf nb = nbf.v4.new_notebook() text = &quot;&quot;&quot; # {title} - toc: {toc} - branch: {branch} - badges: {badges} - comments: {comments} - categories: [{tags}] - description: {description} &quot;&quot;&quot;.format(title=title, toc=toc, branch=branch, badges=badges, comments=comments, tags=tags, description=description) print(text) nb[&#39;cells&#39;] = [nbf.v4.new_markdown_cell(text)] nbf.write(nb, &#39;{}-{}.ipynb&#39;.format(date,format_title)) . Notebook-files-automatically-generated-Jupyter # 自动生成Jupyter笔记本文件 - toc: true - branch: master - badges: true - comments: true - categories: [jupyter] - description: 使用代码自动生成的Jupyter笔记本文件 .",
            "url": "https://henryalps.github.io/fastpages/2020/05/29/tools.html",
            "relUrl": "/2020/05/29/tools.html",
            "date": " • May 29, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "自动生成Jupyter笔记本文件",
            "content": "&#21407;&#22240; . 由于手动创建符合FastPages的笔记本文件比较麻烦（对文件名，格式都有要求），因此，使用代码简单生成一个脚手架文件。 . &#26041;&#27861; . ① 打开目录下的‘tools.ipynb’文件； . ② 修改标题、描述等配置信息； . ③ 运行后即可生成笔记本文件 . tips . 可以在_config.yml中排除tools.ipynb，避免它也生成一个页面。 .",
            "url": "https://henryalps.github.io/fastpages/jupyter/2020/05/24/Notebook-files-automatically-generated-Jupyter.html",
            "relUrl": "/jupyter/2020/05/24/Notebook-files-automatically-generated-Jupyter.html",
            "date": " • May 24, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "基本算法练习",
            "content": "&#24555;&#36895;&#25490;&#24207; . 基本思想 选择哨兵，将比它大的放到左边，小的放到右边。再对左右重复进行上述过程。 . def fast_sort(seq, start, end): if start &gt;= end: return seq # end选为哨兵 sequential_idx = end left_idx = start right_idx = end - 1 while left_idx &lt; right_idx: if seq[left_idx] &gt; seq[sequential_idx] and seq[right_idx] &lt; seq[sequential_idx]: tmp = seq[left_idx] seq[left_idx] = seq[right_idx] seq[right_idx] = tmp left_idx += 1 right_idx -= 1 elif seq[right_idx] &lt; seq[sequential_idx]: left_idx += 1 elif seq[left_idx] &gt; seq[sequential_idx]: right_idx -= 1 else: left_idx += 1 right_idx -= 1 lower_idx = min([left_idx, right_idx]) if seq[sequential_idx] &gt; seq[lower_idx]: tmp = seq[sequential_idx] seq[sequential_idx] = seq[lower_idx + 1] seq[lower_idx + 1] = tmp fast_sort(seq, start, lower_idx) fast_sort(seq, lower_idx + 2, end) else: tmp = seq[sequential_idx] seq[sequential_idx] = seq[lower_idx] seq[lower_idx] = tmp fast_sort(seq, start, lower_idx - 1) fast_sort(seq, lower_idx + 1, end) return seq if &#39;__main__&#39; == __name__: seq = [1,3,4,2,1] print(fast_sort(seq, 0, len(seq) - 1)) seq = [] print(fast_sort(seq, 0, len(seq) - 1)) seq = [2,1] print(fast_sort(seq, 0, len(seq) - 1)) seq = [2,1,1,1,1] print(fast_sort(seq, 0, len(seq) - 1)) . [1, 1, 2, 3, 4] [] [1, 2] [1, 1, 1, 1, 2] . &#34920;&#36798;&#24335;&#27714;&#20540; . 给定一个带括号和加号的表达式，对其进行求值。 . def eval(exp): symbol_stack = [] exp_stack = [] val_stack = [-1] for ch in exp: if ch == &#39;(&#39;: symbol_stack.append(ch) elif ch == &#39;)&#39;: exp = exp_stack.pop() right = val_stack.pop() left = val_stack.pop() if exp == &#39;+&#39;: val_stack.append(right + left) elif ch == &#39;+&#39;: exp_stack.append(ch) else: val_stack.append(int(ch)) while len(exp_stack) &gt; 0: right = val_stack.pop() left = val_stack.pop() if (exp_stack.pop() == &#39;+&#39;): val_stack.append(right + left) return val_stack.pop() if __name__ == &quot;__main__&quot;: print(eval(&#39;(1+2)+(4+5)+6&#39;)) . 18 .",
            "url": "https://henryalps.github.io/fastpages/python/jupyter/2020/05/16/python-code-snippets.html",
            "relUrl": "/python/jupyter/2020/05/16/python-code-snippets.html",
            "date": " • May 16, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "如何用python的for实现死循环",
            "content": "import logging logger = logging.getLogger(__name__) logger.setLevel(logging.WARNING) console = logging.StreamHandler() logger.addHandler(console) formatter = logging.Formatter(fmt=&#39;%(asctime)s %(message)s&#39;,datefmt=&#39;%Y-%m-%d,%H:%M:%S.%f&#39;) console.setFormatter(formatter) # 遍历一个数组时，操作这个数组不断在后边插入，同时删除已遍历的元素 inc_list = [0] for i in inc_list: logging.warning(&#39;looping...&#39;) del i inc_list.append(0) . WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-1-21798d70db2e&gt; in &lt;module&gt; 10 inc_list = [0] 11 for i in inc_list: &gt; 12 logging.warning(&#39;looping...&#39;) 13 del i 14 inc_list.append(0) ~ Anaconda3 envs tensorflow lib logging __init__.py in warning(msg, *args, **kwargs) 1885 if len(root.handlers) == 0: 1886 basicConfig() -&gt; 1887 root.warning(msg, *args, **kwargs) 1888 1889 def warn(msg, *args, **kwargs): ~ Anaconda3 envs tensorflow lib logging __init__.py in warning(self, msg, *args, **kwargs) 1318 &#34;&#34;&#34; 1319 if self.isEnabledFor(WARNING): -&gt; 1320 self._log(WARNING, msg, args, **kwargs) 1321 1322 def warn(self, msg, *args, **kwargs): ~ Anaconda3 envs tensorflow lib logging __init__.py in _log(self, level, msg, args, exc_info, extra, stack_info) 1442 record = self.makeRecord(self.name, level, fn, lno, msg, args, 1443 exc_info, func, extra, sinfo) -&gt; 1444 self.handle(record) 1445 1446 def handle(self, record): ~ Anaconda3 envs tensorflow lib logging __init__.py in handle(self, record) 1452 &#34;&#34;&#34; 1453 if (not self.disabled) and self.filter(record): -&gt; 1454 self.callHandlers(record) 1455 1456 def addHandler(self, hdlr): ~ Anaconda3 envs tensorflow lib logging __init__.py in callHandlers(self, record) 1514 found = found + 1 1515 if record.levelno &gt;= hdlr.level: -&gt; 1516 hdlr.handle(record) 1517 if not c.propagate: 1518 c = None #break out ~ Anaconda3 envs tensorflow lib logging __init__.py in handle(self, record) 863 self.acquire() 864 try: --&gt; 865 self.emit(record) 866 finally: 867 self.release() ~ Anaconda3 envs tensorflow lib logging __init__.py in emit(self, record) 994 msg = self.format(record) 995 stream = self.stream --&gt; 996 stream.write(msg) 997 stream.write(self.terminator) 998 self.flush() ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in write(self, string) 408 self.flush() 409 else: --&gt; 410 self._schedule_flush() 411 412 def writelines(self, sequence): ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in _schedule_flush(self) 332 def _schedule_in_thread(): 333 self._io_loop.call_later(self.flush_interval, self._flush) --&gt; 334 self.pub_thread.schedule(_schedule_in_thread) 335 336 def flush(self): ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in schedule(self, f) 203 self._events.append(f) 204 # wake event thread (message content is ignored) --&gt; 205 self._event_pipe.send(b&#39;&#39;) 206 else: 207 f() ~ Anaconda3 envs tensorflow lib site-packages zmq sugar socket.py in send(self, data, flags, copy, track, routing_id, group) 398 copy_threshold=self.copy_threshold) 399 data.group = group --&gt; 400 return super(Socket, self).send(data, flags=flags, copy=copy, track=track) 401 402 def send_multipart(self, msg_parts, flags=0, copy=True, track=False, **kwargs): zmq/backend/cython/socket.pyx in zmq.backend.cython.socket.Socket.send() zmq/backend/cython/socket.pyx in zmq.backend.cython.socket.Socket.send() zmq/backend/cython/socket.pyx in zmq.backend.cython.socket._send_copy() ~ Anaconda3 envs tensorflow lib site-packages zmq backend cython checkrc.pxd in zmq.backend.cython.checkrc._check_rc() KeyboardInterrupt: .",
            "url": "https://henryalps.github.io/fastpages/python/jupyter/2020/05/16/how-to-write-infinete-loop-with-python-for.html",
            "relUrl": "/python/jupyter/2020/05/16/how-to-write-infinete-loop-with-python-for.html",
            "date": " • May 16, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "图示各种Tensor操作",
            "content": "Tensor&#30340;&#24418;&#29366; . Tensor是什么？ | . 机器学习中的定义下，Tensor是数据的容器。我将其理解为每个元素大小都相等的N维数组。 但在严格的数学定义中，Tensor又不仅仅是数据的容器，Tensor具备几何意义，其中的每个元素实际上表示了某个基向量的权重。 . 为什么要用Tensor? | . 机器学习中，使用Tensor纯粹是需要定义这样一种数据类型--换个名字都可以。 根据某YouTude视频，由于Tensor表征了不同基向量之间的组合。这意味着即使空间发生变换（不涉及升降维），Tensor中存储的信息也不会发生改变，所以Tensor实际是对信息的一种最精简的表示（如果对空间进行变换，基向量互相垂直的关系是否会发生改变？） .",
            "url": "https://henryalps.github.io/fastpages/tensorflow/jupyter/2020/05/04/tensor-operation.html",
            "relUrl": "/tensorflow/jupyter/2020/05/04/tensor-operation.html",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "强推使用FastPages搭建博客",
            "content": "&#20160;&#20040;&#26159;FastPages . FASTAI出品的一个易用的博客框架，尤其突出的特性是对JupyterNoteBook的支持。 . &#22914;&#20309;&#23433;&#35013;FastPages . 非常简单。 . （1）通过这个链接生成一份fork； . （2）GitHub会在约30s后为你的fork开一个Pull Request； . （3）进入Pull Request，按要求首先创建一对 RSA 密钥对。你可以在本地用ssh-key-gen命令创建； . （4）配置RSA密钥对。注意private key命名必须是SSH_DEPLOY_KEY，不然后边部署时会报错； . （5）Merge这个Pull Request，30s后就可以见到你的博客了； . （5）如果Merge过程中出现错误，可以到Actions页面里边点击重试. . &#22914;&#20309;&#37197;&#32622;FastPages . FastPages安装完成后，初始页面看起来是这个样子的： . TK: add title 修改① - 在_config.yml中修改title字段 . 修改② - 在_pages中修改about.md . 修改③ - 在根目录下修改index.html . 修改④ - 在_config.yml中修改description字段 . 修改⑤ - 在_config.yml中修改social_links字段 . &#38382;&#39064; . (1)如果你遇到了类似这样的错误-- . jekyll_1 | Liquid Exception: Permission denied @ rb_sysopen - /data/.tweet-cache/ee341900d3bc668607abd8cba365fd1b.cache in /data/_posts/2020-01-14-test-markdown-post.md jekyll_1 | /usr/local/bundle/ruby/2.6.0/gems/jekyll-twitter-plugin-2.1.0/lib/jekyll-twitter-plugin.rb:41:in `initialize&#39;: Permission denied @ rb_sysopen - /data/.tweet-cache/ee341900d3bc668607abd8cba365fd1b.cache (Errno::EACCES) . 请在目录下执行以下命令： . mkdir .jekyll-cache _site .tweet-cache &amp;&amp; touch .jekyll-metadata . 如果仍有问题，则在docker-compose.yml中，jekyll -&gt; command节点下，加入以下语句： . chmod 777 * .tweet-cache . (2) 如果你发现笔记本中粘贴的图片无法展示 -- 请升级到最新版本的fastpages。 . (3) 如果你发现在粘贴图片后CI状态变为Fail -- . 请按照代码方式更新你的nb2post.py文件。 . (4) 如何用Jupyter Lab快速打开目录（windows） . Jupyter Lab默认打开的是用户目录，如何实现快速打开任意路径下的fastpages文件呢？建符号链接 -- . 复制fastpages的_notebooks路径 {dir} . | 用户目录下打开文件资源管理器，ctrl+L，输入cmd打开命令提示符 . | 输入mklink notebook {dir} . | jupyter lab启动后直接打开notebook文件夹即可 . | . &#24635;&#32467; . FastPages博客的配置和更新方式都和维护一般Git项目类似，对NoteBook的支持应该会催生一批数据科学家用户。 . PS:这篇文章同步发表于Gridea .",
            "url": "https://henryalps.github.io/fastpages/jupyter/2020/05/04/fastpages.html",
            "relUrl": "/jupyter/2020/05/04/fastpages.html",
            "date": " • May 4, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "關於",
          "content": "詩雲： 世間豈得桃源路，陶庵夢斷終不覓。 . Arxiv歎何其多，知乎亦苦難窮盡。 花落水走了無痕，千帆過罷空餘恨。 惟願心做金石意，要留新語在人間。 .",
          "url": "https://henryalps.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://henryalps.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}