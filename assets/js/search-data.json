{
  
    
        "post0": {
            "title": "分享一些整理的资料",
            "content": "&#26446;&#32819;&#12298;&#36947;&#24503;&#32463;&#12299;&#36213;&#23391;&#38955;&#26999;&#20070;&#29256;&#26412; . 《道德经》分为《道经》与《德经》两卷，共五千字。该版本由元代书法家赵孟頫创作于公元1316年，结构严谨，字迹清晰，现藏于故宫博物院。将其扫描档整理为pdf版本文件。 . 图片取自360doc . 链接: 百度网盘 提取码: xakj .",
            "url": "https://henryalps.github.io/fastpages/share/files/2021/06/27/To-share-some-of-information.html",
            "relUrl": "/share/files/2021/06/27/To-share-some-of-information.html",
            "date": " • Jun 27, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "”create a new blog!“",
            "content": "!pip uninstall translation . from googletrans import Translator from datetime import datetime from functools import lru_cache title=&#39;Pytorch一小时入门&#39; description=&#39;抄写一遍Pytorch入门代码&#39; toc=&#39;true&#39; tags=&#39;,&#39;.join([&#39;jupyter&#39;,&#39;pytorch&#39;]) branch=&#39;master&#39; badges=&#39;true&#39; comments=&#39;true&#39; use_math=&#39;true&#39; date=datetime.today().strftime(&#39;%Y-%m-%d&#39;) @lru_cache(maxsize=10) def translate(text): return &#39;-&#39;.join(Translator().translate(text).text.split()) if len(title) &lt; 1: print(&#39;title not set!&#39;) exit() format_title = translate(title) print(format_title) import nbformat as nbf nb = nbf.v4.new_notebook() text = &quot;&quot;&quot; # {title} - toc: {toc} - branch: {branch} - badges: {badges} - use_math: {use_math} - comments: {comments} - categories: [{tags}] - description: {description} &quot;&quot;&quot;.format(title=title, toc=toc, branch=branch, badges=badges, use_math=use_math, comments=comments, tags=tags, description=description) print(text) nb[&#39;cells&#39;] = [nbf.v4.new_markdown_cell(text)] nbf.write(nb, &#39;{}-{}.ipynb&#39;.format(date,format_title)) . Getting-Pytorch-one-hour # Pytorch一小时入门 - toc: true - branch: master - badges: true - comments: true - categories: [jupyter,pytorch] - description: 抄写一遍Pytorch入门代码 .",
            "url": "https://henryalps.github.io/fastpages/2021/06/26/tools.html",
            "relUrl": "/2021/06/26/tools.html",
            "date": " • Jun 26, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "xgBoost学习笔记",
            "content": "&#32972;&#26223; . 来源: XGBoost in Python from Start to Finish . Introduction . importing data from a file | missing data | xgBoost data format | building a model | optimizing a model | . &#28151;&#28102;&#30697;&#38453;(Confusion Matrix) . rows: Predict result | columns: Actual result | outputs: TP/TN/FP/FN | . # install needed modules !pip install pandas numpy sklearn xgboost fsspec matplotlib ipympl . import pandas as pd import numpy as np import xgboost as xgboost from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer, confusion_matrix, plot_confusion_matrix . Import the data . # download the data !wget &#39;https://raw.githubusercontent.com/bhargitay/telco_customer_churn/master/data/WA_Fn-UseC_-Telco-Customer-Churn.csv&#39; . # read by pandas df = pd.read_csv(&#39;G://temp//WA_Fn-UseC_-Telco-Customer-Churn.csv&#39;) . # show datafram df.head() . customerID gender SeniorCitizen Partner Dependents tenure PhoneService MultipleLines InternetService OnlineSecurity ... DeviceProtection TechSupport StreamingTV StreamingMovies Contract PaperlessBilling PaymentMethod MonthlyCharges TotalCharges Churn . 0 7590-VHVEG | Female | 0 | Yes | No | 1 | No | No phone service | DSL | No | ... | No | No | No | No | Month-to-month | Yes | Electronic check | 29.85 | 29.85 | No | . 1 5575-GNVDE | Male | 0 | No | No | 34 | Yes | No | DSL | Yes | ... | Yes | No | No | No | One year | No | Mailed check | 56.95 | 1889.5 | No | . 2 3668-QPYBK | Male | 0 | No | No | 2 | Yes | No | DSL | Yes | ... | No | No | No | No | Month-to-month | Yes | Mailed check | 53.85 | 108.15 | Yes | . 3 7795-CFOCW | Male | 0 | No | No | 45 | No | No phone service | DSL | Yes | ... | Yes | Yes | No | No | One year | No | Bank transfer (automatic) | 42.30 | 1840.75 | No | . 4 9237-HQITU | Female | 0 | No | No | 2 | Yes | No | Fiber optic | No | ... | No | No | No | No | Month-to-month | Yes | Electronic check | 70.70 | 151.65 | Yes | . 5 rows × 21 columns . # drop unwanted column # axis=1 -&gt; column inplace -&gt; update the dataframe df.drop([&#39;customerID&#39;], axis=1, inplace=True) . # find those only contains unique value df[&#39;gender&#39;].unique() . array([&#39;Female&#39;, &#39;Male&#39;], dtype=object) . # remove space from column names and values df[&#39;MultipleLines&#39;].replace(&#39; &#39;, &#39;_&#39;, regex=True, inplace=True) df.columns = df.columns.str.replace(&#39; &#39;, &#39;_&#39;) df.head() . customerID gender SeniorCitizen Partner Dependents tenure PhoneService MultipleLines InternetService OnlineSecurity ... DeviceProtection TechSupport StreamingTV StreamingMovies Contract PaperlessBilling PaymentMethod MonthlyCharges TotalCharges Churn . 0 7590-VHVEG | Female | 0 | Yes | No | 1 | No | No_phone_service | DSL | No | ... | No | No | No | No | Month-to-month | Yes | Electronic check | 29.85 | 29.85 | No | . 1 5575-GNVDE | Male | 0 | No | No | 34 | Yes | No | DSL | Yes | ... | Yes | No | No | No | One year | No | Mailed check | 56.95 | 1889.5 | No | . 2 3668-QPYBK | Male | 0 | No | No | 2 | Yes | No | DSL | Yes | ... | No | No | No | No | Month-to-month | Yes | Mailed check | 53.85 | 108.15 | Yes | . 3 7795-CFOCW | Male | 0 | No | No | 45 | No | No_phone_service | DSL | Yes | ... | Yes | Yes | No | No | One year | No | Bank transfer (automatic) | 42.30 | 1840.75 | No | . 4 9237-HQITU | Female | 0 | No | No | 2 | Yes | No | Fiber optic | No | ... | No | No | No | No | Month-to-month | Yes | Electronic check | 70.70 | 151.65 | Yes | . 5 rows × 21 columns . # remove all space from data df.replace(&#39; &#39;, &#39;_&#39;, regex=True, inplace=True) . Missing data . Missing data就是类似NA, 或者空白字符的字段. 在xgBoost中, Missing data应该置为0. . 为查找Missing data, 使用dtypes方法: . df.dtypes . gender object SeniorCitizen int64 Partner object Dependents object tenure int64 PhoneService object MultipleLines object InternetService object OnlineSecurity object OnlineBackup object DeviceProtection object TechSupport object StreamingTV object StreamingMovies object Contract object PaperlessBilling object PaymentMethod object MonthlyCharges float64 TotalCharges object Churn object dtype: object . 对所有类型为object的列, 逐项检查是否合理. . 找到不合理的列及可能有问题的值后, 找到这些值的位置: . # find location df.loc[(df[&#39;TotalCharges&#39;] == &#39; &#39;)] . gender SeniorCitizen Partner Dependents tenure PhoneService MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV StreamingMovies Contract PaperlessBilling PaymentMethod MonthlyCharges TotalCharges Churn . 488 Female | 0 | Yes | Yes | 0 | No | No_phone_service | DSL | Yes | No | Yes | Yes | Yes | No | Two year | Yes | Bank transfer (automatic) | 52.55 | | No | . 753 Male | 0 | No | Yes | 0 | Yes | No | No | No internet service | No internet service | No internet service | No internet service | No internet service | No internet service | Two year | No | Mailed check | 20.25 | | No | . 936 Female | 0 | Yes | Yes | 0 | Yes | No | DSL | Yes | Yes | Yes | No | Yes | Yes | Two year | No | Mailed check | 80.85 | | No | . 1082 Male | 0 | Yes | Yes | 0 | Yes | Yes | No | No internet service | No internet service | No internet service | No internet service | No internet service | No internet service | Two year | No | Mailed check | 25.75 | | No | . 1340 Female | 0 | Yes | Yes | 0 | No | No_phone_service | DSL | Yes | Yes | Yes | Yes | Yes | No | Two year | No | Credit card (automatic) | 56.05 | | No | . 3331 Male | 0 | Yes | Yes | 0 | Yes | No | No | No internet service | No internet service | No internet service | No internet service | No internet service | No internet service | Two year | No | Mailed check | 19.85 | | No | . 3826 Male | 0 | Yes | Yes | 0 | Yes | Yes | No | No internet service | No internet service | No internet service | No internet service | No internet service | No internet service | Two year | No | Mailed check | 25.35 | | No | . 4380 Female | 0 | Yes | Yes | 0 | Yes | No | No | No internet service | No internet service | No internet service | No internet service | No internet service | No internet service | Two year | No | Mailed check | 20.00 | | No | . 5218 Male | 0 | Yes | Yes | 0 | Yes | No | No | No internet service | No internet service | No internet service | No internet service | No internet service | No internet service | One year | Yes | Mailed check | 19.70 | | No | . 6670 Female | 0 | Yes | Yes | 0 | Yes | Yes | DSL | No | Yes | Yes | Yes | Yes | No | Two year | No | Mailed check | 73.35 | | No | . 6754 Male | 0 | No | Yes | 0 | Yes | Yes | DSL | Yes | Yes | No | Yes | No | No | Two year | Yes | Bank transfer (automatic) | 61.90 | | No | . # set to 0 df.loc[(df[&#39;TotalCharges&#39;] == &#39; &#39;), &#39;TotalCharges&#39;] = 0 df[&#39;TotalCharges&#39;] = pd.to_numeric(df[&#39;TotalCharges&#39;]) df.dtypes . gender object SeniorCitizen int64 Partner object Dependents object tenure int64 PhoneService object MultipleLines object InternetService object OnlineSecurity object OnlineBackup object DeviceProtection object TechSupport object StreamingTV object StreamingMovies object Contract object PaperlessBilling object PaymentMethod object MonthlyCharges float64 TotalCharges float64 Churn object dtype: object . xgBoost data format . 首先将特征和估计值分开: . X = df.drop(&#39;Churn&#39;, axis=1).copy() X.head() . gender SeniorCitizen Partner Dependents tenure PhoneService MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV StreamingMovies Contract PaperlessBilling PaymentMethod MonthlyCharges TotalCharges . 0 Female | 0 | Yes | No | 1 | No | No_phone_service | DSL | No | Yes | No | No | No | No | Month-to-month | Yes | Electronic_check | 29.85 | 29.85 | . 1 Male | 0 | No | No | 34 | Yes | No | DSL | Yes | No | Yes | No | No | No | One_year | No | Mailed_check | 56.95 | 1889.50 | . 2 Male | 0 | No | No | 2 | Yes | No | DSL | Yes | Yes | No | No | No | No | Month-to-month | Yes | Mailed_check | 53.85 | 108.15 | . 3 Male | 0 | No | No | 45 | No | No_phone_service | DSL | Yes | No | Yes | Yes | No | No | One_year | No | Bank_transfer_(automatic) | 42.30 | 1840.75 | . 4 Female | 0 | No | No | 2 | Yes | No | Fiber_optic | No | No | No | No | No | No | Month-to-month | Yes | Electronic_check | 70.70 | 151.65 | . y = df[&#39;Churn&#39;].copy() y.head() . 0 No 1 No 2 Yes 3 No 4 Yes Name: Churn, dtype: object . 其次, 将Category特征转化为One-hot编码. One-hot编码的原因是它能保证所有目标值互相之间的距离相同, 从而避免模型不必要地拉近不同预测值的距离. 用get_dummies转化one-hot编码. . y_encoded=pd.get_dummies(y)[&#39;Yes&#39;] . X_encoded=pd.get_dummies(X, columns=[&#39;gender&#39;,&#39;Partner&#39;,&#39;Dependents&#39;,&#39;PhoneService&#39;,&#39;MultipleLines&#39;,&#39;InternetService&#39;,&#39;OnlineSecurity&#39;,&#39;OnlineBackup&#39;,&#39;DeviceProtection&#39;,&#39;TechSupport&#39;,&#39;StreamingTV&#39;,&#39;StreamingMovies&#39;,&#39;Contract&#39;,&#39;PaperlessBilling&#39;,&#39;PaymentMethod&#39;]) . X_encoded.head() . SeniorCitizen tenure MonthlyCharges TotalCharges gender_Female gender_Male Partner_No Partner_Yes Dependents_No Dependents_Yes ... StreamingMovies_Yes Contract_Month-to-month Contract_One_year Contract_Two_year PaperlessBilling_No PaperlessBilling_Yes PaymentMethod_Bank_transfer_(automatic) PaymentMethod_Credit_card_(automatic) PaymentMethod_Electronic_check PaymentMethod_Mailed_check . 0 0 | 1 | 29.85 | 29.85 | 1 | 0 | 0 | 1 | 1 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | . 1 0 | 34 | 56.95 | 1889.50 | 0 | 1 | 1 | 0 | 1 | 0 | ... | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | . 2 0 | 2 | 53.85 | 108.15 | 0 | 1 | 1 | 0 | 1 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | . 3 0 | 45 | 42.30 | 1840.75 | 0 | 1 | 1 | 0 | 1 | 0 | ... | 0 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 4 0 | 2 | 70.70 | 151.65 | 1 | 0 | 1 | 0 | 1 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | . 5 rows × 45 columns . y_encoded.unique() . array([0, 1], dtype=uint8) . tips:默认值设置为0在one-hot编码中的优势 - 默认值为0会将所有位置的编码都设置为0, 从而使得0不会干扰到其它有实际值的项目. . build xgBoost model . 首先, 将数据划分为训练集 和 测试集. 划分集合时, 需要注意按照目标预测值的比例来进行划分, 保证划分后的比例与划分前尽量一致: . X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, random_state=42, stratify=y_encoded) . print(len(X_train), len(X_test)) . 5282 1761 . 接下来开始构建xgBoost模型. . early stop: 如果10棵树都没有产生优化效果, 则退出 | . clf_xgb = xgboost.XGBClassifier(objective=&#39;binary:logistic&#39;, missing=None, seed=42) clf_xgb.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=&#39;aucpr&#39;, eval_set=[(X_test, y_test)]) . C: Users henryalps Anaconda3 envs xeus-python lib site-packages xgboost sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) . [0] validation_0-aucpr:0.63160 [1] validation_0-aucpr:0.64538 [2] validation_0-aucpr:0.64402 [3] validation_0-aucpr:0.64429 [4] validation_0-aucpr:0.63866 [5] validation_0-aucpr:0.63419 [6] validation_0-aucpr:0.63912 [7] validation_0-aucpr:0.63787 [8] validation_0-aucpr:0.63779 [9] validation_0-aucpr:0.63894 [10] validation_0-aucpr:0.63680 . XGBClassifier(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1, importance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;, learning_rate=0.300000012, max_delta_step=0, max_depth=6, min_child_weight=1, missing=None, monotone_constraints=&#39;()&#39;, n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1, tree_method=&#39;exact&#39;, validate_parameters=1, verbosity=None) . 最后绘制confusion matrix: . %matplotlib inline plot_confusion_matrix(clf_xgb, X_test, y_test, values_format=&#39;d&#39;, display_labels=[&#39;Did not leave&#39;,&#39;left&#39;]) . &lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x27d32087f70&gt; . optimize xgBoost model . 模型对left的分类并不好, 但是left的影响更大, 所以需要对模型进行优化. 优化可以通过结合Cross validation和GridSearch两种方法来达成. . # GridSearch param_grid = { &#39;max_depth&#39;: [3,4,5], &#39;learning_rate&#39;: [0.1,0.01,0.05], &#39;gamma&#39;: [0, 0.25, 1.0], &#39;reg_lambda&#39;: [0, 1.0, 10.0], &#39;scale_pos_weight&#39;: [1,3,5] } # 使用subsample参数, 可以指定每棵树对应的样本数量占整体的比重 # 使用colsample_bytree, 可以指定每棵树选取多少特征 # 使用cv, 可指定cross validation是多少折 optimal_params = GridSearchCV(estimator=xgboost.XGBClassifier(objective=&#39;binary:logistic&#39;, seed=42, subsample=0.9, colsample_bytree=0.5), param_grid=param_grid, scoring=&#39;roc_auc&#39;, cv=3) .",
            "url": "https://henryalps.github.io/fastpages/statquest/xgboost/2021/04/05/XGBOOST-learning-notes.html",
            "relUrl": "/statquest/xgboost/2021/04/05/XGBOOST-learning-notes.html",
            "date": " • Apr 5, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "关于KL散度非负性证明",
            "content": "&#32972;&#26223; . 在学习时, 对末尾的公式有疑问, 查询记录在这里.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &#38382;&#39064; . KL散度的公式如下: $$ D_{ mathrm{KL}}(P | Q)= int_{- infty}^{ infty} p(x) log left( frac{p(x)}{q(x)} right) d x $$ . 在证明其非负时, 用到了jansen不等式, 如下: $$ varphi( mathrm{E}[X]) leq mathrm{E}[ varphi(X)] $$ . 关键点是这里的推导: $$ begin{aligned} int p(x) log frac{p(x)}{q(x)} d x &amp;=- int p(x) log frac{q(x)}{p(x)} d x &amp; leqslant- log int p(x) frac{q(x)}{p(x)} d x=0 end{aligned} $$ . &#38382;&#39064;&#30340;&#35299;&#20915; . 首先, jansen不等式中的 $X$ 可以用 $g(x)$ 替换, 得到 $$ varphi(E[g(x)]) leq E[ varphi(g(x))] quad(1)$$ . 其次, 定义 $$g(x) = frac{q(x)}{p(x)} quad(2)$$ $$ varphi(x) = log(x) quad(3)$$ . 再次就到了这里的一个关键点, 即复合函数如何求期望. 根据维基百科, $$E[g(x)] = int g(x) p(x) d x quad(4)$$ $$E[ varphi(g(x))]= int p(x) varphi(g(x)) d x quad(5)$$ 这里隐含着条件x是以$p(x)$为PDF的随机变量. . 将(2)代入(4) (5)得到 $$ begin{aligned} E[ varphi(g(x))] &amp;= int f(x) varphi(g(x)) d x &amp;= int p(x) log left( frac{q(x)}{p(x)} right) d x end{aligned}(6)$$ . $$E[g(x)]= int frac{q(x)}{p(x)} p(x) d x quad(7)$$ . 再代入(1)便得到了问题中的结论. . &#24635;&#32467; . 这个式子感觉并不直观, 要想到它, 首先要了解log是一个凸函数, 其次对jansen不等式十分熟悉, 最后能够在PDF和期望之间建立关联, 我就是在最后一步被卡住了. . &lt;/div&gt; .",
            "url": "https://henryalps.github.io/fastpages/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/kl-divergence/2021/04/05/On-the-non-negative-proof-of-KL-divergence.html",
            "relUrl": "/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/kl-divergence/2021/04/05/On-the-non-negative-proof-of-KL-divergence.html",
            "date": " • Apr 5, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "TensorFlow教程复习",
            "content": "将分tf2.0与tf1.0两大章节，分别重现TensorFlow教程中的关键章节。 . 8062097330.png . TensorFlow2.0&#22797;&#20064; . keras&#26426;&#22120;&#23398;&#20064;&#22522;&#26412;&#30693;&#35782; . &#22270;&#20687;&#20998;&#31867; . 该教程训练一个神经网络用于对衣物图像进行分类，如将鞋与衬衫分开。该教程使用tf.keras包，它是TF上构建和训练模型的高级API. . import tensorflow as tf from tensorflow import keras import numpy as np import matplotlib.pyplot as plt print(tf.__version__) . 2.0.0 . &#23548;&#20837;MNIST&#27969;&#34892;&#25968;&#25454;&#38598; . fashion_mnist = keras.datasets.fashion_mnist (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() . 载入这个数据集后，会得到4个Ndarray: . train_images和train_labels数组是训练集 -- 即模型用于学习的数据 | 使用test_images和test_labels测试集测试模型。 | . 图像是28x28的ndarray，每一个像素的范围都是0,255。标签是一个整形数组，范围为0到9，与图像表征的衣服类型一一对应。 . 每一幅图像被映射到单个标签上。由于类名不包含于数据集，我们先把类名列出来以待后续使用。 . class_names = [&#39;T-shirt/top&#39;, &#39;Trouser&#39;, &#39;Pullover&#39;, &#39;Dress&#39;, &#39;Coat&#39;, &#39;Sandal&#39;, &#39;Shirt&#39;, &#39;Sneaker&#39;, &#39;Bag&#39;, &#39;Ankle boot&#39;] . &#25506;&#32034;&#25968;&#25454; . 训练模型前我们先检查下数据集的格式。以下结果说明训练集中共0.6billion张图片，每幅图片由28*28个像素组成： . train_images.shape . (60000, 28, 28) . # 训练集中有60000个标签 len(train_labels) . 60000 . # 每个标签都是0到9之间的整数 train_labels . array([9, 0, 0, ..., 3, 0, 5], dtype=uint8) . # 测试集中有10000张图片，每一幅图也是28*28像素 test_images.shape . (10000, 28, 28) . # 测试集包含10000个标签 len(test_labels) . 10000 . &#25968;&#25454;&#39044;&#22788;&#29702; . 在将数据送入网络前，必须对其进行预处理。如果你查看训练集中的第一幅图片，你会发现像素值在0到255之间： . plt.figure() plt.imshow(train_images[0]) plt.colorbar() plt.grid(False) plt.show() . 在将值送入神经网络模型前，有必要将他们缩放到0到1之间。为了做这个操作，直接将值除255即可。训练和测试集必须以同种方式处理： . train_images = train_images / 255.0 test_images = test_images / 255.0 . 为了验证数据是正确格式，且你已经准备好训练和构建网络，我们绘制前43幅图片，并在图片下方显示其类名： . plt.figure(figsize=(10,10)) for i in range(43): plt.subplot(9,5,i+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(train_images[i], cmap = plt.cm.binary) plt.xlabel(class_names[train_labels[i]]) plt.show() . &#26500;&#24314;&#27169;&#22411; . 构建神经网络模型需要我们配置网络层，然后编译模型。 . &#35774;&#32622;&#32593;&#32476;&#23618; . 神经网络的基本构建单元叫做层。层根据输入数据抽取表征。这些表征对解决手头的问题一般很有意义。 . 大部分深度学习网络包含级联在一起的简单层。大部分层，例如tf.keras.layers.Dense都包含训练过程中学习的参数。 . model = keras.Sequential([ keras.layers.Flatten(input_shape=(28,28)), keras.layers.Dense(128, activation=&#39;relu&#39;), keras.layers.Dense(10) ]) . 网络中的第一层，tf.keras.layers.Flatten将图片格式从2维数组转化为1维数组（784个像素）。可以想象它是拆分开像素的各行，再将它们连接起来。这一层没什么特别的参数要学习，它只是重新格式化数据。 在像素被压平之后，网络随即连接两个tf.keras.layers.Dense层。这些是紧密连接（或者称作全连接）的神经网络层。第一个Dense层有128个节点或者神经元。第二个（输出层）返回一个长度维10的序列，每个值都表示当前图片属于该类别的概率。 . &#32534;&#35793;&#27169;&#22411; . 在模型可以训练之前，还需要对它进行一些设置。这些设置是在compile步骤完成的： . 损失函数 - 这个函数衡量模型在训练过程中有多么精确。你的目标是最小化这个函数以使模型朝正确的方向优化。 | 优化器 - 这表示模型如何根据它看到的数据和损失函数去更新参数 | 评估指标 - 用于监控训练和测试步骤，以下的例子用准确率作为指标，即被正确分类的图片占全部图片的比例。 | . model.compile(optimizer=&#39;adam&#39;, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[&#39;accuracy&#39;]) . &#35757;&#32451;&#27169;&#22411; . 训练神经网络模型需要以下几个步骤： . 将训练数据喂给模型。在例子中，训练数据对应于train_images和train_labels两个数组； | 模型学习关联图片和标签； | 你要求模型对测试集进行预测 -- 在这个例子中，既是test_images这个数组； | 验证预测值与test_labels序列的标签对应。 #### 提供数据 为开始训练，调用model.fit方法，叫fit的原因是它将模型适配到训练数据的分布上： | model.fit(train_images, train_labels, epochs=10) . Train on 60000 samples Epoch 1/10 60000/60000 [==============================] - 6s 105us/sample - loss: 2.4907 - accuracy: 0.7033 Epoch 2/10 60000/60000 [==============================] - 4s 67us/sample - loss: 0.6701 - accuracy: 0.7666 Epoch 3/10 60000/60000 [==============================] - 4s 68us/sample - loss: 0.5754 - accuracy: 0.8036 Epoch 4/10 60000/60000 [==============================] - 4s 72us/sample - loss: 0.5379 - accuracy: 0.8192 Epoch 5/10 60000/60000 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.82 - 4s 67us/sample - loss: 0.5178 - accuracy: 0.8288 Epoch 6/10 60000/60000 [==============================] - 4s 73us/sample - loss: 0.5025 - accuracy: 0.8339 Epoch 7/10 60000/60000 [==============================] - 4s 74us/sample - loss: 0.4878 - accuracy: 0.8375 Epoch 8/10 60000/60000 [==============================] - 4s 72us/sample - loss: 0.4842 - accuracy: 0.8405 Epoch 9/10 60000/60000 [==============================] - 4s 71us/sample - loss: 0.4791 - accuracy: 0.8441 Epoch 10/10 60000/60000 [==============================] - 4s 71us/sample - loss: 0.4747 - accuracy: 0.8437 . &lt;tensorflow.python.keras.callbacks.History at 0x2627486a5c8&gt; . 随着模型训练，损失和进度指标不断更新，模型最终在训练集达到了91%的精度。 . &#35780;&#20272;&#31934;&#24230; . 其后，我们对比一下模型在测试集上的表现： . test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2) print(&#39; nTest accuracy:&#39;, test_acc) . 10000/1 - 1s - loss: 0.4512 - accuracy: 0.8165 Test accuracy: 0.8165 . 我们发现测试集上的精度要稍低于训练集上的精度。两个精度之间的差值说明出现了过拟合。在机器学习模型用于新的从未见过的输入时，它的表现变差，认为出现了过拟合。过拟合的模型记住了训练数据中的噪音和细节，以至于影响到模型在新数据上的效果。 . &#39044;&#27979;&#32467;&#26524; . 模型训练完后，我们可以用它来对一些新图片的类别进行预测。模型的原始输出向量称为对数logits。通过加入一个softmax层，可以将对数转化为概率分布，使结果更加便于理解。 . probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()]) . predictions = probability_model.predict(test_images) . # 模型对所有测试集中的图片预测了类别，我们看看第一个预测的结果： predictions[0] . array([3.95853505e-07, 5.04734352e-08, 4.52002773e-08, 1.04268434e-10, 6.14671819e-07, 4.81123308e-04, 6.37260541e-07, 8.51320755e-03, 1.08166132e-09, 9.91003871e-01], dtype=float32) . 模型预测的类别是一个长度为10的数组。它们表征了模型给图片分属于10个类的“置信度”评价。可以用以下方式知道哪个标签有最大的置信度： . np.argmax(predictions[0]) . 9 . # 所以模型认为图片最可能对应一个ankle boot靴子，或者class_names[9]. # 我们检查一下测试集标签，来证明模型的看法是对的： test_labels[0] . 9 . 绘制图片来看看所有的预测结果： . def plot_images(i, predictions_array, true_label, img): predictions_array, true_label, img = predictions_array, true_label[i], img[i] plt.grid(False) plt.xticks([]) plt.yticks([]) plt.imshow(img, cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) if predicted_label == true_label: color = &#39;blue&#39; else: color = &#39;red&#39; plt.xlabel(&quot;{} {:2.0f}%({})&quot;.format(class_names[predicted_label], 100*np.max(predictions_array), class_names[true_label], color=color)) def plot_value_array(i, predictions_array, true_label): predictions_array, true_label = predictions_array, true_label[i] plt.grid(False) plt.xticks(range(10)) plt.yticks([]) thisplot = plt.bar(range(10), predictions_array, color=&#39;#777777&#39;) plt.ylim([0,1]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(&#39;red&#39;) thisplot[true_label].set_color(&#39;blue&#39;) . &#39564;&#35777;&#39044;&#27979;&#32467;&#26524; . 模型训练完后，你可以用它进行预测。 . 我们先看看第1个图片，预测结果，以及对应的概率分布。正确的预测标签是蓝色的，不正确的是红色的。数值给出了预测标签的占比： . i = 0 plt.figure(figsize=(6,3)) plt.subplot(1,2,1) plot_images(i, predictions[i], test_labels, test_images) plt.subplot(1,2,2) plot_value_array(i,predictions[i], test_labels) plt.show() . i = 12 plt.figure(figsize=(6,3)) plt.subplot(1,2,1) plot_images(i, predictions[i], test_labels, test_images) plt.subplot(1,2,2) plot_value_array(i,predictions[i], test_labels) plt.show() . 绘制一些图片和它们的预测结果就会发现，即便模型置信度很高，也可能是错误结果。 . num_rows = 5 num_cols = 3 num_images = num_rows*num_cols plt.figure(figsize=[2*2*num_cols, 2*num_rows]) for i in range(num_images): plt.subplot(num_rows, 2*num_cols, 2*i+1) plot_images(i, predictions[i], test_labels, test_images) plt.subplot(num_rows, 2*num_cols, 2*i+2) plot_value_array(i,predictions[i], test_labels) plt.tight_layout() plt.show() . &#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411; . 我们终于可以用训练好的模型对单个图片进行分类了： . img = test_images[142] plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x2626cb6f908&gt; . tf.keras模型已经经过优化，们可以对一个“batch”或者几何进行预测。所以即使你只是用单张图片，你也需要将它添加到列表中： . img = (np.expand_dims(img, 0)) print(img.shape) . (1, 28, 28) . # 现在对图片的正确标签进行预测： predictions_single = probability_model.predict(img) print(predictions_single) . [[8.6784530e-01 3.4884884e-04 1.2338771e-05 2.0001229e-02 4.8068767e-05 4.6012540e-17 1.1174188e-01 2.8636104e-37 2.3276600e-06 5.6846246e-34]] . plot_value_array(1, predictions_single[0], test_labels) _ = plt.xticks(range(10), class_names, rotation=30) . # keras.model.predict 返回一个二维数组，其中每个一维数组都对应 # batch中的一个图片。通过以下方式拿到我们对该批中唯一一幅图片的 # 预测结果： np.argmax(predictions_single[0]) . 0 . &#25991;&#26412;&#20998;&#31867; . &#20351;&#29992; Keras &#21644; Tensorflow Hub &#23545;&#30005;&#24433;&#35780;&#35770;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867; . 已有中文版本,此处仅列出代码。 . from __future__ import absolute_import, division, print_function, unicode_literals import numpy as np import tensorflow as tf import tensorflow_hub as hub import tensorflow_datasets as tfds print(&quot;Version: &quot;, tf.__version__) print(&quot;Eager mode: &quot;, tf.executing_eagerly()) print(&quot;Hub version: &quot;, hub.__version__) print(&quot;GPU is&quot;, &quot;available&quot; if tf.config.experimental.list_physical_devices(&quot;GPU&quot;) else &quot;NOT AVAILABLE&quot;) . Version: 2.0.0 Eager mode: True Hub version: 0.8.0 GPU is available . dir(tfds.Split.TRAIN) . [&#39;TEST&#39;, &#39;TRAIN&#39;, &#39;VALIDATION&#39;, &#39;__add__&#39;, &#39;__class__&#39;, &#39;__contains__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__getitem__&#39;, &#39;__getnewargs__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__len__&#39;, &#39;__lt__&#39;, &#39;__mod__&#39;, &#39;__module__&#39;, &#39;__mul__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__rmod__&#39;, &#39;__rmul__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;capitalize&#39;, &#39;casefold&#39;, &#39;center&#39;, &#39;count&#39;, &#39;encode&#39;, &#39;endswith&#39;, &#39;expandtabs&#39;, &#39;find&#39;, &#39;format&#39;, &#39;format_map&#39;, &#39;index&#39;, &#39;isalnum&#39;, &#39;isalpha&#39;, &#39;isascii&#39;, &#39;isdecimal&#39;, &#39;isdigit&#39;, &#39;isidentifier&#39;, &#39;islower&#39;, &#39;isnumeric&#39;, &#39;isprintable&#39;, &#39;isspace&#39;, &#39;istitle&#39;, &#39;isupper&#39;, &#39;join&#39;, &#39;ljust&#39;, &#39;lower&#39;, &#39;lstrip&#39;, &#39;maketrans&#39;, &#39;partition&#39;, &#39;replace&#39;, &#39;rfind&#39;, &#39;rindex&#39;, &#39;rjust&#39;, &#39;rpartition&#39;, &#39;rsplit&#39;, &#39;rstrip&#39;, &#39;split&#39;, &#39;splitlines&#39;, &#39;startswith&#39;, &#39;strip&#39;, &#39;swapcase&#39;, &#39;title&#39;, &#39;translate&#39;, &#39;upper&#39;, &#39;zfill&#39;] . ?tfds.Split.TRAIN.subsplit . Object `tfds.Split.TRAIN.subsplit` not found. . # 将训练集按照 6:4 的比例进行切割，从而最终我们将得到 15,000 # 个训练样本, 10,000 个验证样本以及 25,000 个测试样本 train_data, validation_data, test_data = tfds.load( name=&quot;imdb_reviews&quot;, split=[&#39;train[:60%]&#39;, &#39;train[60%:]&#39;, tfds.Split.TEST], as_supervised=True) . Downloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to C: Users henryalps tensorflow_datasets imdb_reviews plain_text 1.0.0... Shuffling and writing examples to C: Users henryalps tensorflow_datasets imdb_reviews plain_text 1.0.0.incompleteNJ9POX imdb_reviews-train.tfrecord Shuffling and writing examples to C: Users henryalps tensorflow_datasets imdb_reviews plain_text 1.0.0.incompleteNJ9POX imdb_reviews-test.tfrecord Shuffling and writing examples to C: Users henryalps tensorflow_datasets imdb_reviews plain_text 1.0.0.incompleteNJ9POX imdb_reviews-unsupervised.tfrecord Dataset imdb_reviews downloaded and prepared to C: Users henryalps tensorflow_datasets imdb_reviews plain_text 1.0.0. Subsequent calls will reuse this data. . train_examples_batch, train_labels_batch = next(iter(train_data.batch(10))) train_examples_batch . &lt;tf.Tensor: id=200, shape=(10,), dtype=string, numpy= array([b&#39;This is a big step down after the surprisingly enjoyable original. This sequel isn &#39;t nearly as fun as part one, and it instead spends too much time on plot development. Tim Thomerson is still the best thing about this series, but his wisecracking is toned down in this entry. The performances are all adequate, but this time the script lets us down. The action is merely routine and the plot is only mildly interesting, so I need lots of silly laughs in order to stay entertained during a &#34;Trancers&#34; movie. Unfortunately, the laughs are few and far between, and so, this film is watchable at best.&#39;, b&#34;Perhaps because I was so young, innocent and BRAINWASHED when I saw it, this movie was the cause of many sleepless nights for me. I haven&#39;t seen it since I was in seventh grade at a Presbyterian school, so I am not sure what effect it would have on me now. However, I will say that it left an impression on me... and most of my friends. It did serve its purpose, at least until we were old enough and knowledgeable enough to analyze and create our own opinions. I was particularly terrified of what the newly-converted post-rapture Christians had to endure when not receiving the mark of the beast. I don&#39;t want to spoil the movie for those who haven&#39;t seen it so I will not mention details of the scenes, but I can still picture them in my head... and it&#39;s been 19 years.&#34;, b&#39;Hood of the Living Dead had a lot to live up to even before the opening credits began. First, any play on &#34;...of the living dead&#34; invokes His Holiness Mr. Romero and instantly sets up a high standard to which many movies cannot afford to aspire. And second, my movie-watching companion professed doubt that any urban horror film would surpass the seminal Leprechaun In the Hood. Skeptical, we settled in to watch. &lt;br /&gt;&lt;br /&gt;We were rewarded with a surprisingly sincere and good-hearted zombie film. Oh, certainly the budget is low, and of course the directors &#39; amateurs friends populate the cast, but Hood of the Living Dead loves zombie cinema. Cheap? Yeah. But when it &#39;s this cheap, you can clearly see where LOVE holds it together. &lt;br /&gt;&lt;br /&gt;Ricky works in a lab during the day and as a surrogate parent to his younger brother at night. He dreams of moving out of Oakland. Before this planned escape, however, his brother is shot to death in a drive-by. Ricky &#39;s keen scientific mind presents an option superior to CPR or 911: injections of his lab &#39;s experimental regenerative formula. Sadly, little bro wakes up in an ambulance as a bloodthirsty Oakland zombie! Chaos and mayhem! I think it &#39;s more economical to eat your enemies than take vengeance in a drive-by, but then again, I &#39;m a poor judge of the complexities of urban life. (How poor a judge? In response to a gory scene involving four men, I opined &#34;Ah-ha! White t-shirts on everyone so the blood shows up. Economical! I used the same technique in my own low-budget horror film.&#34; Jordan replied, &#34;No, that &#39;s gang dress. White t-shirts were banned from New Orleans bars for a time as a result.&#34; Oh.)&lt;br /&gt;&lt;br /&gt;A lot of the movie is set in someone &#39;s living room, so there &#39;s a great deal of hanging out and waiting for the zombies. But the characters are sympathetic and the movie is sincere-- it surpasses its budget in spirit. &lt;br /&gt;&lt;br /&gt;Zombie explanation: When man plays God, zombies arise! Or, perhaps: Follow FDA-approved testing rules before human experimentation! &lt;br /&gt;&lt;br /&gt;Contribution to the zombie canon: This is the first zombie movie I &#39;ve seen with a drive-by shooting. As far as the actual zombies go, infection is spread with a bite as usual, but quite unusually head shots don &#39;t work-- it &#39;s heart shots that kill. Zombies have pulses, the absence of which proves true death. And these zombies make pretty cool jaguar-growl noises. &lt;br /&gt;&lt;br /&gt;Gratuitous zombie movie in-joke: A mercenary named Romero. Groan. &lt;br /&gt;&lt;br /&gt;Favorite zombie: Jaguar-noise little brother zombie, of course!&#39;, b&#34;For me this is a story that starts with some funny jokes regarding Franks fanatasies when he is travelling with a staircase and when he is sitting in business meetings... The problem is that when you have been watching this movie for an hour you will see the same fantasies/funny situations again and again and again. It is to predictable. It is more done as a TV story where you can go away and come back without missing anything.&lt;br /&gt;&lt;br /&gt;I like Felix Herngren as Frank but that is not enough even when it is a comedy it has to have more variations and some kind of message to it&#39;s audience....&lt;br /&gt;&lt;br /&gt;&#34;, b&#39;This is not a bad movie. It follows the new conventions of modern horror, that is the movie within a movie, the well known actress running for her life in the first scene. This movie takes the old convention of a psycho killer on he loose, and manage to do something new, and interesting with it. It is also always nice to see Molly Ringwald back for the attack.&lt;br /&gt;&lt;br /&gt;So this might be an example of what the genre has become. Cut hits all the marks, and is actually scary in some parts. I liked it I gave it an eight.&#39;, b&#34;I just finished a marathon of this series, and it became agonising to watch as it progressed. From the fictionalising of the historical elements, to O&#39;Herlihy&#39;s awful accent in later episodes, the show just slumps the further it goes. If you are looking for some low quality production generalised WW2 fluff, then I could recommend season 1, but avoid anything after that, it degenerates into being one step from a soap opera, with increasingly worse story lines and sensibility.&lt;br /&gt;&lt;br /&gt;The old B&amp;W film is by far the best of any form of entertainment with the Colditz name attached to it, and even that is not what one could hope for.&#34;, b&#39;I am very sorry that this charming and whimsical film (which I first saw soon after it was first released in the early fifties) has had such a poor reception more recently. In my opinion it has been greatly underrated - but perhaps it appeals more to the European sense of humour than to (for example) the American: maybe we in Europe can understand and appreciate its subtleties and situations more, since we are closer to some of them in real life! Particular mention should be made of the limited but good music - especially the catchy and memorable song &#34;It &#39;s a fine, fine night&#34;, which was issued separately on an HMV 78rpm record (10 inch plum label, I think!) in the fifties. I would urge anyone interested to give it a try if you get the chance: you may have a pleasant surprise.&#39;, b&#34;Well i am going to go against the grain on this film so it seems. Being a self confessed horror fan I sat down to this not quite knowing what to expect. After 2 or 3 mins i actually found myself scared (quite rare). The film obviously has a small budget and is set around charing cross station but the films lack of money does not distract from the story. Yes the story is a bit far fetched and doesn&#39;t explain itself very well but THE CREEP is a class act and proceeds to slash and dismember anything that comes its way. MESSAGE FOR LADIES !!! THERE ARE CERTAIN PARTS OF THE FILM YOU SHOULD CLOSE YOUR EYES AT OR AT LEAST CROSS YOUR LEGS !! you will understand when you see it.&lt;br /&gt;&lt;br /&gt;All in all a good film and it makes a change to see a good slasher movie that actually scares&#34;, b&#39;Even 15 years after the end of the Vietnam war &#34;Jacknife&#34; came not too late or was even superfluous. It &#39;s one of the few that try to deal with the second sad side of the war: The time after. Different from movies like &#34;Taxi driver&#34; or &#34;Rambo&#34; which use to present their main characters as broken heroes in a bad after war environment this movie allows the audience to face a different view on the Vietnam vets. Their development is shown very precisely before and especially after the war. The problems are obvious but in all this tragic there is always the feeling of some hope on the basis of love and friendship. &#34;Jacknife&#34; might be the quietest Vietnam movie ever but after almost 15 years this is really plausible and therefor justified. Moreover, it can make us believe that the war has not finished, yet; at least for some of us.&lt;br /&gt;&lt;br /&gt;The three main characters are amazing. De Niro has done one of his best jobs but Ed Harris is the star of this movie. Possibly,this was his best performance ever.&#39;, b&#39;Before I explain the &#34;Alias&#34; comment let me say that &#34;The Desert Trail&#34; is bad even by the standards of westerns staring The Three Stooges. In fact it features Carmen Laroux as semi- bad girl Juanita, when you hear her Mexican accent you will immediately recognize her as Senorita Rita from the classic Stooge short &#34;Saved by the Belle&#34;. &lt;br /&gt;&lt;br /&gt;In &#34;The Desert Trail&#34; John Wayne gets to play the Moe Howard character and Eddy Chandler gets to play Curly Howard. Like their Stooge counterparts a running gag throughout the 53- minute movie is Moe hitting Curly. Wayne &#39;s character, a skirt chasing bully, is not very endearing, but is supposed to be the good guy. &lt;br /&gt;&lt;br /&gt;Playing a traveling rodeo cowboy Wayne holds up the rodeo box office at gunpoint and takes the prize money he would have won if the attendance proceeds had been good-the other riders have to settle for 25 cents on the dollar (actually even less after Wayne robs the box office). No explanation is given for Wayne &#39;s ripping off the riders and still being considered the hero who gets the girl. &lt;br /&gt;&lt;br /&gt;Things get complicated at this point because the villain (Al Ferguson) and his sidekick Larry Fine (played by Paul Fix-who would go on to play Sheriff Micah on television &#39;s &#34;The Rifleman&#34;) see Wayne rob the box office and then steal the remainder of the money and kill the rodeo manager. Moe and Curly get blamed. &lt;br /&gt;&lt;br /&gt;So Moe and Curly move to another town to get away from the law and they change their names to Smith and Jones. Who do they meet first but their old friend Larry, whose sister becomes the 2nd half love interest (Senorita Rita is left behind it the old town and makes no further appearances in the movie). &lt;br /&gt;&lt;br /&gt;Larry &#39;s sister is nicely played by a radiantly beautiful Mary Kornman (now grown up but in her younger days she was one of the original cast members of Hal Roach &#39;s &#34;Our Gang&#34; shorts). Kornman is the main reason to watch the mega-lame western and her scenes with Moe and Curly are much better than any others in the production, as if they used an entirely different crew to film them. &lt;br /&gt;&lt;br /&gt;Even for 1935 the action sequences in this thing are extremely weak and the technical film- making is staggeringly bad. The two main chase scenes end with stock footage wide shots of a rider falling from a horse. Both times the editor cuts to a shot of one of the characters rolling on the ground, but there is no horse in the frame, the film stock is completely different, and the character has on different clothes than the stunt rider. There is liberal use of stock footage in other places, none of it even remotely convincing. &lt;br /&gt;&lt;br /&gt;One thing to watch for is a scene midway into the movie where Moe and Curly get on their horses and ride away (to screen right) from a cabin as the posse is galloping toward the cabin from the left. The cameraman follows the two stooges with a slow pan right and then does a whip pan to the left to reveal the approaching posse. Outside of home movies I have never seen anything like this, not because it is looks stupid (which it does) but because a competent director would never stage a scene in this manner. They would film the two riders leaving and then reposition the camera and film the posse approaching as a separate action. Or if they were feeling creative they would stage the sequence so the camera shows the riders in the foreground and the posse approaching in the background. &lt;br /&gt;&lt;br /&gt;Then again, what do I know? I &#39;m only a child.&#39;], dtype=object)&gt; . train_labels_batch . &lt;tf.Tensor: id=201, shape=(10,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0, 1, 1, 1, 0], dtype=int64)&gt; . embedding = &quot;https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1&quot; hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True) # 注意这里直接以函数形式调用hub_layer即可得到输出 hub_layer(train_examples_batch[:3]) . &lt;tf.Tensor: id=383, shape=(3, 20), dtype=float32, numpy= array([[ 2.209591 , -2.7093675 , 3.6802928 , -1.0291991 , -4.1671185 , -2.4566064 , -2.2519937 , -0.36589956, 1.9485804 , -3.1104462 , -2.4610963 , 1.3139242 , -0.9161584 , -0.16625322, -3.723651 , 1.8498232 , 3.499562 , -1.2373022 , -2.8403084 , -1.213074 ], [ 1.9055302 , -4.11395 , 3.6038654 , 0.28555924, -4.658998 , -5.5433393 , -3.2735848 , 1.9235417 , 3.8461034 , 1.5882455 , -2.64167 , 0.76057523, -0.14820506, 0.9115291 , -6.45758 , 2.3990374 , 5.0985413 , -3.2776263 , -3.2652326 , -1.2345369 ], [ 3.6510668 , -4.7066135 , 4.71003 , -1.7002777 , -3.7708545 , -3.709126 , -4.222776 , 1.946586 , 6.1182513 , -2.7392752 , -5.4384456 , 2.7078724 , -2.1263676 , -0.7084146 , -5.893995 , 3.1602864 , 3.8389287 , -3.318196 , -5.1542974 , -2.4051712 ]], dtype=float32)&gt; . model = tf.keras.Sequential() model.add(hub_layer) model.add(tf.keras.layers.Dense(16, activation=&#39;relu&#39;)) model.add(tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;)) model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= keras_layer (KerasLayer) (None, 20) 400020 _________________________________________________________________ dense (Dense) (None, 16) 336 _________________________________________________________________ dense_1 (Dense) (None, 1) 17 ================================================================= Total params: 400,373 Trainable params: 400,373 Non-trainable params: 0 _________________________________________________________________ . model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) history = model.fit(train_data.shuffle(10000).batch(512), epochs=20, validation_data=validation_data.batch(512), verbose=1) . Epoch 1/20 30/30 [==============================] - 6s 198ms/step - loss: 0.7342 - accuracy: 0.5693 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00 Epoch 2/20 30/30 [==============================] - 5s 150ms/step - loss: 0.6288 - accuracy: 0.6535 - val_loss: 0.6012 - val_accuracy: 0.6827 Epoch 3/20 30/30 [==============================] - 4s 147ms/step - loss: 0.5822 - accuracy: 0.7035 - val_loss: 0.5648 - val_accuracy: 0.7171 Epoch 4/20 30/30 [==============================] - 5s 151ms/step - loss: 0.5438 - accuracy: 0.7380 - val_loss: 0.5320 - val_accuracy: 0.7472 Epoch 5/20 30/30 [==============================] - 5s 151ms/step - loss: 0.5065 - accuracy: 0.7693 - val_loss: 0.5013 - val_accuracy: 0.7729 Epoch 6/20 30/30 [==============================] - 5s 151ms/step - loss: 0.4721 - accuracy: 0.7935 - val_loss: 0.4707 - val_accuracy: 0.7926 Epoch 7/20 30/30 [==============================] - 5s 151ms/step - loss: 0.4359 - accuracy: 0.8181 - val_loss: 0.4423 - val_accuracy: 0.8078 Epoch 8/20 30/30 [==============================] - 4s 150ms/step - loss: 0.3999 - accuracy: 0.8367 - val_loss: 0.4140 - val_accuracy: 0.8228 Epoch 9/20 30/30 [==============================] - 5s 150ms/step - loss: 0.3695 - accuracy: 0.8518 - val_loss: 0.3899 - val_accuracy: 0.8359 Epoch 10/20 30/30 [==============================] - 5s 150ms/step - loss: 0.3370 - accuracy: 0.8676 - val_loss: 0.3697 - val_accuracy: 0.8469 Epoch 11/20 30/30 [==============================] - 5s 155ms/step - loss: 0.3065 - accuracy: 0.8818 - val_loss: 0.3514 - val_accuracy: 0.8549 Epoch 12/20 30/30 [==============================] - 4s 147ms/step - loss: 0.2848 - accuracy: 0.8946 - val_loss: 0.3368 - val_accuracy: 0.8635 Epoch 13/20 30/30 [==============================] - 4s 148ms/step - loss: 0.2639 - accuracy: 0.9033 - val_loss: 0.3259 - val_accuracy: 0.8670 Epoch 14/20 30/30 [==============================] - 5s 151ms/step - loss: 0.2419 - accuracy: 0.9109 - val_loss: 0.3173 - val_accuracy: 0.8704 Epoch 15/20 30/30 [==============================] - 5s 151ms/step - loss: 0.2265 - accuracy: 0.9188 - val_loss: 0.3144 - val_accuracy: 0.8699 Epoch 16/20 30/30 [==============================] - 4s 148ms/step - loss: 0.2098 - accuracy: 0.9256 - val_loss: 0.3046 - val_accuracy: 0.8738 Epoch 17/20 30/30 [==============================] - 4s 147ms/step - loss: 0.1939 - accuracy: 0.9333 - val_loss: 0.3023 - val_accuracy: 0.8758 Epoch 18/20 30/30 [==============================] - 5s 150ms/step - loss: 0.1821 - accuracy: 0.9383 - val_loss: 0.2993 - val_accuracy: 0.8773 Epoch 19/20 30/30 [==============================] - 4s 147ms/step - loss: 0.1722 - accuracy: 0.9429 - val_loss: 0.2977 - val_accuracy: 0.8782 Epoch 20/20 30/30 [==============================] - 4s 150ms/step - loss: 0.1580 - accuracy: 0.9497 - val_loss: 0.2988 - val_accuracy: 0.8786 . results = model.evaluate(test_data.batch(512), verbose=2) for name, value in zip(model.metrics_names, results): print(&quot;%s: %.3f&quot; % (name, value)) . 49/49 - 4s - loss: 0.3167 - accuracy: 0.8648 loss: 0.317 accuracy: 0.865 . &#30005;&#24433;&#35780;&#35770;&#25991;&#26412;&#20998;&#31867; . 已有中文版本，此处仅列出代码： . from __future__ import absolute_import, division, print_function, unicode_literals import tensorflow as tf from tensorflow import keras import numpy as np print(tf.__version__) . 2.0.0 . imdb = keras.datasets.imdb (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz 17465344/17464789 [==============================] - 2s 0us/step . print(&quot;Training entries: {}, labels: {}&quot;.format(len(train_data), len(train_labels))) . Training entries: 25000, labels: 25000 . print(train_data[0]) print(train_labels[0]) . [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 1 . # 一个映射单词到整数索引的词典 word_index = imdb.get_word_index() # 保留第一个索引 word_index = {k:(v+3) for k,v in word_index.items()} word_index[&quot;&lt;PAD&gt;&quot;] = 0 word_index[&quot;&lt;START&gt;&quot;] = 1 word_index[&quot;&lt;UNK&gt;&quot;] = 2 # unknown word_index[&quot;&lt;UNUSED&gt;&quot;] = 3 reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) def decode_review(text): return &#39; &#39;.join([reverse_word_index.get(i, &#39;?&#39;) for i in text]) . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json 1646592/1641221 [==============================] - 0s 0us/step . decode_review(train_data[0]) . &#34;&lt;START&gt; this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert &lt;UNK&gt; is an amazing actor and now the same being director &lt;UNK&gt; father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for &lt;UNK&gt; and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also &lt;UNK&gt; to the two little boy&#39;s that played the &lt;UNK&gt; of norman and paul they were just brilliant children are often left out of the &lt;UNK&gt; list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all&#34; . train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[&quot;&lt;PAD&gt;&quot;], padding=&#39;post&#39;, maxlen=256) test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[&quot;&lt;PAD&gt;&quot;], padding=&#39;post&#39;, maxlen=256) . ?keras.preprocessing.sequence.pad_sequences . Signature: keras.preprocessing.sequence.pad_sequences( sequences, maxlen=None, dtype=&#39;int32&#39;, padding=&#39;pre&#39;, truncating=&#39;pre&#39;, value=0.0, ) Docstring: Pads sequences to the same length. This function transforms a list of `num_samples` sequences (lists of integers) into a 2D Numpy array of shape `(num_samples, num_timesteps)`. `num_timesteps` is either the `maxlen` argument if provided, or the length of the longest sequence otherwise. Sequences that are shorter than `num_timesteps` are padded with `value` at the end. Sequences longer than `num_timesteps` are truncated so that they fit the desired length. The position where padding or truncation happens is determined by the arguments `padding` and `truncating`, respectively. Pre-padding is the default. # Arguments sequences: List of lists, where each element is a sequence. maxlen: Int, maximum length of all sequences. dtype: Type of the output sequences. To pad sequences with variable length strings, you can use `object`. padding: String, &#39;pre&#39; or &#39;post&#39;: pad either before or after each sequence. truncating: String, &#39;pre&#39; or &#39;post&#39;: remove values from sequences larger than `maxlen`, either at the beginning or at the end of the sequences. value: Float or String, padding value. # Returns x: Numpy array with shape `(len(sequences), maxlen)` # Raises ValueError: In case of invalid values for `truncating` or `padding`, or in case of invalid shape for a `sequences` entry. File: c: users henryalps anaconda3 envs tensorflow20 lib site-packages keras_preprocessing sequence.py Type: function . len(train_data[0]), len(train_data[1]) . (256, 256) . print(train_data[0]) . [ 1 14 22 16 43 530 973 1622 1385 65 458 4468 66 3941 4 173 36 256 5 25 100 43 838 112 50 670 2 9 35 480 284 5 150 4 172 112 167 2 336 385 39 4 172 4536 1111 17 546 38 13 447 4 192 50 16 6 147 2025 19 14 22 4 1920 4613 469 4 22 71 87 12 16 43 530 38 76 15 13 1247 4 22 17 515 17 12 16 626 18 2 5 62 386 12 8 316 8 106 5 4 2223 5244 16 480 66 3785 33 4 130 12 16 38 619 5 25 124 51 36 135 48 25 1415 33 6 22 12 215 28 77 52 5 14 407 16 82 2 8 4 107 117 5952 15 256 4 2 7 3766 5 723 36 71 43 530 476 26 400 317 46 7 4 2 1029 13 104 88 4 381 15 297 98 32 2071 56 26 141 6 194 7486 18 4 226 22 21 134 476 26 480 5 144 30 5535 18 51 36 28 224 92 25 104 4 226 65 16 38 1334 88 12 16 283 5 16 4472 113 103 32 15 16 5345 19 178 32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . # 输入形状是用于电影评论的词汇数目（10,000 词） vocab_size = 10000 model = keras.Sequential() model.add(keras.layers.Embedding(vocab_size, 16)) model.add(keras.layers.GlobalAveragePooling1D()) model.add(keras.layers.Dense(16, activation=&#39;relu&#39;)) model.add(keras.layers.Dense(1, activation=&#39;sigmoid&#39;)) model.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, None, 16) 160000 _________________________________________________________________ global_average_pooling1d (Gl (None, 16) 0 _________________________________________________________________ dense_2 (Dense) (None, 16) 272 _________________________________________________________________ dense_3 (Dense) (None, 1) 17 ================================================================= Total params: 160,289 Trainable params: 160,289 Non-trainable params: 0 _________________________________________________________________ . 9235193169.png . model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) x_val = train_data[:10000] partial_x_train = train_data[10000:] y_val = train_labels[:10000] partial_y_train = train_labels[10000:] history = model.fit(partial_x_train, partial_y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1) . Train on 15000 samples, validate on 10000 samples Epoch 1/40 15000/15000 [==============================] - 2s 157us/sample - loss: 0.6917 - accuracy: 0.5409 - val_loss: 0.6893 - val_accuracy: 0.6497 Epoch 2/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.6843 - accuracy: 0.7176 - val_loss: 0.6789 - val_accuracy: 0.7162 Epoch 3/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.6698 - accuracy: 0.7300 - val_loss: 0.6614 - val_accuracy: 0.7448 Epoch 4/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.6463 - accuracy: 0.7591 - val_loss: 0.6353 - val_accuracy: 0.7636 Epoch 5/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.6136 - accuracy: 0.7847 - val_loss: 0.6019 - val_accuracy: 0.7899 Epoch 6/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.5736 - accuracy: 0.8143 - val_loss: 0.5633 - val_accuracy: 0.8082 Epoch 7/40 15000/15000 [==============================] - 1s 93us/sample - loss: 0.5301 - accuracy: 0.8335 - val_loss: 0.5227 - val_accuracy: 0.8207 Epoch 8/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.4857 - accuracy: 0.8509 - val_loss: 0.4839 - val_accuracy: 0.8340 Epoch 9/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.4442 - accuracy: 0.8620 - val_loss: 0.4494 - val_accuracy: 0.8456 Epoch 10/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.4070 - accuracy: 0.8723 - val_loss: 0.4194 - val_accuracy: 0.8519 Epoch 11/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.3750 - accuracy: 0.8808 - val_loss: 0.3944 - val_accuracy: 0.8584 Epoch 12/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.3473 - accuracy: 0.8897 - val_loss: 0.3740 - val_accuracy: 0.8630 Epoch 13/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.3240 - accuracy: 0.8946 - val_loss: 0.3573 - val_accuracy: 0.8679 Epoch 14/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.3035 - accuracy: 0.8991 - val_loss: 0.3434 - val_accuracy: 0.8706 Epoch 15/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.2857 - accuracy: 0.9041 - val_loss: 0.3325 - val_accuracy: 0.8720 Epoch 16/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.2699 - accuracy: 0.9094 - val_loss: 0.3227 - val_accuracy: 0.8751 Epoch 17/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.2559 - accuracy: 0.9133 - val_loss: 0.3159 - val_accuracy: 0.8757 Epoch 18/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.2433 - accuracy: 0.9179 - val_loss: 0.3080 - val_accuracy: 0.8790 Epoch 19/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.2313 - accuracy: 0.9223 - val_loss: 0.3029 - val_accuracy: 0.8802 Epoch 20/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.2208 - accuracy: 0.9253 - val_loss: 0.2983 - val_accuracy: 0.8820 Epoch 21/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.2108 - accuracy: 0.9289 - val_loss: 0.2944 - val_accuracy: 0.8830 Epoch 22/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.2020 - accuracy: 0.9322 - val_loss: 0.2914 - val_accuracy: 0.8837 Epoch 23/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.1931 - accuracy: 0.9363 - val_loss: 0.2890 - val_accuracy: 0.8845 Epoch 24/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1852 - accuracy: 0.9397 - val_loss: 0.2884 - val_accuracy: 0.8829 Epoch 25/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1791 - accuracy: 0.9421 - val_loss: 0.2861 - val_accuracy: 0.8837 Epoch 26/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1709 - accuracy: 0.9466 - val_loss: 0.2857 - val_accuracy: 0.8835 Epoch 27/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1643 - accuracy: 0.9495 - val_loss: 0.2844 - val_accuracy: 0.8850 Epoch 28/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1579 - accuracy: 0.9523 - val_loss: 0.2839 - val_accuracy: 0.8870 Epoch 29/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.1518 - accuracy: 0.9546 - val_loss: 0.2847 - val_accuracy: 0.8842 Epoch 30/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.1471 - accuracy: 0.9557 - val_loss: 0.2845 - val_accuracy: 0.8866 Epoch 31/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1407 - accuracy: 0.9578 - val_loss: 0.2852 - val_accuracy: 0.8874 Epoch 32/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.1361 - accuracy: 0.9600 - val_loss: 0.2866 - val_accuracy: 0.8859 Epoch 33/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1312 - accuracy: 0.9617 - val_loss: 0.2874 - val_accuracy: 0.8854 Epoch 34/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1261 - accuracy: 0.9640 - val_loss: 0.2895 - val_accuracy: 0.8851 Epoch 35/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1218 - accuracy: 0.9661 - val_loss: 0.2905 - val_accuracy: 0.8854 Epoch 36/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.1175 - accuracy: 0.9678 - val_loss: 0.2924 - val_accuracy: 0.8855 Epoch 37/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1132 - accuracy: 0.9695 - val_loss: 0.2946 - val_accuracy: 0.8848 Epoch 38/40 15000/15000 [==============================] - 1s 94us/sample - loss: 0.1093 - accuracy: 0.9705 - val_loss: 0.2968 - val_accuracy: 0.8839 Epoch 39/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1056 - accuracy: 0.9720 - val_loss: 0.2998 - val_accuracy: 0.8841 Epoch 40/40 15000/15000 [==============================] - 1s 95us/sample - loss: 0.1023 - accuracy: 0.9733 - val_loss: 0.3016 - val_accuracy: 0.8836 . results = model.evaluate(test_data, test_labels, verbose=2) print(results) . 25000/1 - 2s - loss: 0.3204 - accuracy: 0.8729 [0.3223323440361023, 0.87288] . history_dict = history.history history_dict.keys() . dict_keys([&#39;loss&#39;, &#39;accuracy&#39;, &#39;val_loss&#39;, &#39;val_accuracy&#39;]) . import matplotlib.pyplot as plt acc = history_dict[&#39;accuracy&#39;] val_acc = history_dict[&#39;val_accuracy&#39;] loss = history_dict[&#39;loss&#39;] val_loss = history_dict[&#39;val_loss&#39;] epochs = range(1, len(acc) + 1) # “bo”代表 &quot;蓝点&quot; plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;) # b代表“蓝色实线” plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;) plt.title(&#39;Training and validation loss&#39;) plt.xlabel(&#39;Epochs&#39;) plt.ylabel(&#39;Loss&#39;) plt.legend() plt.show() . plt.clf() # 清除数字 plt.plot(epochs, acc, &#39;bo&#39;, label=&#39;Training acc&#39;) plt.plot(epochs, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;) plt.title(&#39;Training and validation accuracy&#39;) plt.xlabel(&#39;Epochs&#39;) plt.ylabel(&#39;Accuracy&#39;) plt.legend() plt.show() .",
            "url": "https://henryalps.github.io/fastpages/jupyter/tensorflow/2020/06/06/TensorFlow-tutorial-review.html",
            "relUrl": "/jupyter/tensorflow/2020/06/06/TensorFlow-tutorial-review.html",
            "date": " • Jun 6, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Pytorch一小时入门",
            "content": "更新记录： . 20/05/31(I) 完成前两节（30min）的内容 . 20/05/31(II) 完成后两节（30min）的内容 . 学习了DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ，将过程记录在此处。 . 9169772538.png . 1.理解PyTorch的Tensor库 | 2.Autograd自动求导的应用 | 3.构建神经网络 | 4.一个实际的例子 | . &#29702;&#35299;PyTorch&#30340;Tensor&#24211; . Tesnsor&#30340;&#23450;&#20041; . Tensors和NumPy的ndarray结构很像，区别是Tensor可以用于GPU计算。 . from __future__ import print_function import torch # check the GPU support dir(torch.cuda) . [&#39;BFloat16Storage&#39;, &#39;BFloat16Tensor&#39;, &#39;BoolStorage&#39;, &#39;BoolTensor&#39;, &#39;ByteStorage&#39;, &#39;ByteTensor&#39;, &#39;CharStorage&#39;, &#39;CharTensor&#39;, &#39;CudaError&#39;, &#39;DeferredCudaCallError&#39;, &#39;DoubleStorage&#39;, &#39;DoubleTensor&#39;, &#39;Event&#39;, &#39;FloatStorage&#39;, &#39;FloatTensor&#39;, &#39;HalfStorage&#39;, &#39;HalfTensor&#39;, &#39;IntStorage&#39;, &#39;IntTensor&#39;, &#39;LongStorage&#39;, &#39;LongTensor&#39;, &#39;PIPE&#39;, &#39;Popen&#39;, &#39;ShortStorage&#39;, &#39;ShortTensor&#39;, &#39;Stream&#39;, &#39;_CudaBase&#39;, &#39;_StorageBase&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;_after_fork&#39;, &#39;_check_capability&#39;, &#39;_check_driver&#39;, &#39;_cudart&#39;, &#39;_dummy_type&#39;, &#39;_free_mutex&#39;, &#39;_get_device_index&#39;, &#39;_host_allocator&#39;, &#39;_in_bad_fork&#39;, &#39;_initialized&#39;, &#39;_lazy_call&#39;, &#39;_lazy_init&#39;, &#39;_lazy_new&#39;, &#39;_load_cudart&#39;, &#39;_original_pid&#39;, &#39;_queued_calls&#39;, &#39;_register_after_fork&#39;, &#39;_sleep&#39;, &#39;_utils&#39;, &#39;check_error&#39;, &#39;comm&#39;, &#39;contextlib&#39;, &#39;ctypes&#39;, &#39;cudaStatus&#39;, &#39;cudart&#39;, &#39;current_blas_handle&#39;, &#39;current_device&#39;, &#39;current_stream&#39;, &#39;default_stream&#39;, &#39;device&#39;, &#39;device_count&#39;, &#39;device_of&#39;, &#39;empty_cache&#39;, &#39;find_cuda_windows_lib&#39;, &#39;get_device_capability&#39;, &#39;get_device_name&#39;, &#39;get_device_properties&#39;, &#39;get_rng_state&#39;, &#39;get_rng_state_all&#39;, &#39;init&#39;, &#39;initial_seed&#39;, &#39;ipc_collect&#39;, &#39;is_available&#39;, &#39;manual_seed&#39;, &#39;manual_seed_all&#39;, &#39;max_memory_allocated&#39;, &#39;max_memory_cached&#39;, &#39;memory_allocated&#39;, &#39;memory_cached&#39;, &#39;nccl&#39;, &#39;nvtx&#39;, &#39;os&#39;, &#39;platform&#39;, &#39;profiler&#39;, &#39;raise_from&#39;, &#39;random&#39;, &#39;reset_max_memory_allocated&#39;, &#39;reset_max_memory_cached&#39;, &#39;seed&#39;, &#39;seed_all&#39;, &#39;set_device&#39;, &#39;set_rng_state&#39;, &#39;set_rng_state_all&#39;, &#39;sparse&#39;, &#39;stream&#39;, &#39;streams&#39;, &#39;synchronize&#39;, &#39;sys&#39;, &#39;torch&#39;, &#39;traceback&#39;, &#39;warnings&#39;] . assert(torch.cuda.is_available()) . 创建一个5x3张量，不初始化 . x=torch.empty(5,3) print(x) . tensor([[ 8.4078e-45, 0.0000e+00, 2.6136e-28], [ 5.5772e-43, -1.3120e-30, 4.5915e-41], [ 0.0000e+00, 0.0000e+00, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 0.0000e+00], [-1.3120e-30, 4.5915e-41, 0.0000e+00]]) . ???这里的表现和页面不一样，预期应该是全0才对 . 创建一个随机初始化张量 . x=torch.rand(5,3) print(x) . tensor([[0.3783, 0.4491, 0.0897], [0.2913, 0.1618, 0.6047], [0.2112, 0.3987, 0.1202], [0.8236, 0.2970, 0.4896], [0.4792, 0.2471, 0.6751]]) . 创建一个填0的long型张量 . x=torch.zeros(5,3,dtype=torch.long) print(x) . tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) . 从数据中直接创建一个张量 . x=torch.tensor([5.5,3.0]) print(x) . tensor([5.5000, 3.0000]) . 根据一个已有张量创建张量 . # 创建一个类型变为double型的全1张量 x=x.new_ones(5,3,dtype=torch.double) print(x) x=torch.randn_like(x,dtype=torch.float) print(x) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.4722, -0.4380, -1.0941], [ 0.6054, 0.6555, -1.1304], [-1.1721, 1.3889, 0.3657], [-1.6273, -0.0502, 0.8097], [ 1.3560, 0.1341, 1.6279]]) . torch.size实际是一个tuple . print(x.size()) print(x.size()[0]) . torch.Size([5, 3]) 5 . Tensor&#25805;&#20316; . 加法之两种符号类型 . # 类型1- 直接用加号 x = torch.ones(5,3) y = torch.zeros(5,3) print(x + y) # 类型2- 使用函数add print(torch.add(x,y)) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . ？？？为何要用两种符号表示呢 . 加法之指定结果tensor . result = torch.empty(5,3) torch.add(x,y,out=result) print(result) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . 加法之原位相加 . y.add_(x) print(y) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . 注意到所有原位运算都是在函数名后边加一个下划线 . 使用类似numpy的范围写法取tensor的部分值 . # 打印x的第一列 print(x[:,1]) # 打印x的第一行 print(x[1,:]) . tensor([1., 1., 1., 1., 1.]) tensor([1., 1., 1.]) . 改变tensor的维度 . x = torch.randn(4,4) y = x.view(16) # 只指定每行的元素数量，就可以计算出变换后的形状 z = x.view(-1, 2) print(x,y,z) . tensor([[ 1.7866, 1.8163, -0.4897, 0.6796], [-1.1594, 1.8653, -0.4756, -0.8084], [ 0.5253, 1.8867, 1.2337, -0.1705], [ 0.6688, 0.0531, -0.9582, -0.4612]]) tensor([ 1.7866, 1.8163, -0.4897, 0.6796, -1.1594, 1.8653, -0.4756, -0.8084, 0.5253, 1.8867, 1.2337, -0.1705, 0.6688, 0.0531, -0.9582, -0.4612]) tensor([[ 1.7866, 1.8163], [-0.4897, 0.6796], [-1.1594, 1.8653], [-0.4756, -0.8084], [ 0.5253, 1.8867], [ 1.2337, -0.1705], [ 0.6688, 0.0531], [-0.9582, -0.4612]]) . tensor的操作还有很多，此处实际没有完全列举 . Numpy&#26725;&#25509; - &#22312;tensor&#19982;numpy&#25968;&#32452;&#20043;&#38388;&#20114;&#30456;&#36716;&#25442; . numpy数组和tensor共享内存：这意味着对任何一个变量的改变都将同步到另一个上。 . 转化tensor为一个ndarray . a=torch.ones(5) b=a.numpy() print(a,b) . tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.] . 对tensor的改变将会反映到ndarray上 . a.add_(a) print(b) . [2. 2. 2. 2. 2.] . 对ndarray的改变将会反映到tensor上 . b+=1 print(a) . tensor([3., 3., 3., 3., 3.]) . 将ndarray转换为tensor . import numpy as np a = np.ones(5) #注意此处的变量命名 b = torch.from_numpy(a) np.add(a,1,out=a) print(a) print(b) . [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) . GPU&#19978;&#30340;tensor . 使用to()方法将tensor迁移到其它设备 . device = torch.device(&quot;cuda&quot;) y = torch.ones_like(x, device=device) x = x.to(device) z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.int)) . tensor([[ 2.7866, 2.8163, 0.5103, 1.6796], [-0.1594, 2.8653, 0.5244, 0.1916], [ 1.5253, 2.8867, 2.2337, 0.8295], [ 1.6688, 1.0531, 0.0418, 0.5388]], device=&#39;cuda:0&#39;) tensor([[2, 2, 0, 1], [0, 2, 0, 0], [1, 2, 2, 0], [1, 1, 0, 0]], dtype=torch.int32) . Autograd&#33258;&#21160;&#27714;&#23548;&#30340;&#24212;&#29992; . pytorch中神经网络的核心模块就是autograd包，我们简单地了解一下这个包，其后就可以开始训练我们的第一个神经网络了。 . autograd包可以对所有的tensor操作进行自动差分（？？？如何自定义运算符）。它是一个define-by-run的框架，也就是你的反向传播是由代码运行方式所决定的，每一个操作都会有不同。 . 我们用更简单的方式和例子进行解释。 . tensor . torch.Tensor是这个包的核心。如果你将其属性.requires_grad设为True，它将追踪其上的所有操作。当你完成计算后，可以调用.backward()方法以自动计算所有导数。这个tensor的导数将由.grad参数所体现。 . 为了结束对一个tensor求导的操作，你可以用.detach方法将它从计算历史中移除，以避免之后它又被继续求导。 . 为了避免对tensor求导占用内存，你可以将代码块用with torch.no_grad()包裹起来。这对模型评估尤其有用，因为其中可能存在设置了require_grad=True的参数，但我们却不需要求导数。 . Function类是另外一个非常常用的类。 . Tensor和Function共同作用以构建一个无环图，该图对完整的计算历史进行编码。每个tensor都有一个.grad_fn属性，其中保存了创建这个tensor的Function对象。（用户自己创建的tensor则没有这个属性） . 如果你想计算导数，你可以调用tensor的.backward()方法。如果tensor是一个标量（即包含单个元素），你不需要为backward()指定任何参数。但如果它有多于一个元素，则你必需为它指定gradient参数，其形状与该tensor对应。 . 创建一个tensor并设定require_grad为True以追踪其上的计算： . x = torch.ones(2,2,requires_grad=True) print(x) . tensor([[1., 1.], [1., 1.]], requires_grad=True) . tensor运算 . y = x + 2 print(y) . tensor([[3., 3.], [3., 3.]], grad_fn=&lt;AddBackward0&gt;) . 更多的tensor运算 . z = y * y * 3 out = z.mean() print(z, out) . tensor([[27., 27.], [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;) . .requires_grad_()可用于替换一个已有tensor的require_grad标志位。输入标志位默认为False。 . a = torch.randn(2,2) a=((a*3)/(a-1)) print(a.requires_grad) print(a.grad_fn) a.requires_grad_(True) print(a.requires_grad) print(a.grad_fn) b=(a*a).sum() print(b.grad_fn) . False None True None &lt;SumBackward0 object at 0x00000240968298D0&gt; . 进行反向传播。由于out是一个标量，所以无需传入参数 . out.backward() print(x.grad) . tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) . 如果我们将out定义为$o$,那么我们将有$o= frac{1}{4} sum_{i}3(x_i+2)^2$,此时$ frac{ partial o}{ partial x_i}= frac{3}{2}(x_i+2)$,因此$ frac{ partial o}{ partial x_i} mid_{x_i=1}=4.5$ . 数学上来说，如果你有一个因自变量都为向量的函数$ vec{y}=f( vec{x})$,那么$ vec{y}$对$ vec{x}$的导数为一个雅可比矩阵： . $J= left( begin{array}{ccc} frac{ partial y_{1}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{1}}{ partial x_{n}} vdots &amp; ddots &amp; vdots frac{ partial y_{m}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{n}} end{array} right)$ . 一般地，torch.autograd是一个用于计算向量-雅可比行列式乘积的工具。也就是说，给定任何向量$v=(v_1 v_2 ... v_m)^T$，如果$v$刚好是标量函数$l=g( vec{y})$的导数，也就是说$v= left( frac{ partial l}{ partial y_{1}} cdots frac{ partial l}{ partial y_{m}} right)^{T}$，那么根据链式法则有向量与雅克比行列式之积为 $J^{T} cdot v= left( begin{array}{ccc} frac{ partial y_{1}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{1}} vdots &amp; ddots &amp; vdots frac{ partial y_{1}}{ partial x_{n}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{n}} end{array} right) left( begin{array}{c} frac{ partial l}{ partial y_{1}} frac{ partial l}{ partial y_{m}} end{array} right)= left( begin{array}{c} frac{ partial l}{ partial x_{1}} frac{ partial l}{ partial x_{n}} end{array} right)$ . 向量与雅克比行列式之积的这种性质使得，将额外的导数引入输出不为常量的模型非常方便。 现在我们看一下向量-雅克比积的一个例子： . x = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm()&lt;1000: y=y*2 print(y) . tensor([-800.3267, 194.5804, 608.2095], grad_fn=&lt;MulBackward0&gt;) . 在这个例子中y不再是一个标量了。torch.autograd不能直接计算完整的雅克比行列式，但如果我们只想要向量-雅克比行列式之积的话，就简单将向量传入backward参数即可： . v = torch.tensor([0.1,1.0,0.0001], dtype=torch.float) y.backward(v) print(x.grad) . tensor([5.1200e+01, 5.1200e+02, 5.1200e-02]) . 关于上面这一段知乎链接讲的比较清楚，主要动机是不允许tensor对tensor求导，只允许scalar对tensor求导。 . 如果想对已经设置requires_grad=True的张量停止自动求导，有两种方式： . 1.使用with torch.no_grad()包裹 . 2.使用.detach()获取一个新的不需导数的张量 . print(x.requires_grad) print((x**2).requires_grad) with torch.no_grad(): print((x**2).requires_grad) print(x.requires_grad) y=x.detach() print(y.requires_grad) print(x.eq(y).all()) . True True False True False tensor(True) . &#31070;&#32463;&#32593;&#32476; . torch.nn用于构建神经网络。 . 现在你已经了解了autograd包，nn依赖autograd以定义模型并对其求差分。nn.Module的一个实例会包含网络层，以及一个forward(input)方法用于返回output。 . 如，看看下边这个定义用于对位图分类的网络： . 4864202438.png . 上图是一个简单的前向网络，它接收输入，依次喂给几层，最终得到输出。 一个典型的训练过程如下： . 定义有一些可训练参数的网络 | 输入一组数据 | 前向传播 | 计算损失函数值 | 反向传播获取梯度 | 更新网络权重，通常使用weight=weight-learning_rate*gradient | . &#23450;&#20041;&#32593;&#32476; . 以下代码用于定义网络： . import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 输入只有一个灰度channel，输出为6个channel，每个channel为3*3卷积获取 self.conv1 = nn.Conv2d(1,6,3) self.conv2 = nn.Conv2d(6,16,3) # 尾部的全连接层 # 3*3卷积得到的输出是6*6 self.fc1 = nn.Linear(16*6*6, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def num_flat_features(self, x): size = x.size()[1:] # batch维不会被压平 num_features = 1 for s in size: num_features *= s return num_features def forward(self, x): # 做最大池化以下采样 x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) # 如果是用的方阵的话也可以只写行数或列数 x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 形状变换 x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() print(net) . Net( (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) (fc1): Linear(in_features=576, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) . 你必需定义forward方法。backward方法会在指定autograd时自动计算得到。forard方法中可以用任意tensor操作。 . 网络可学习的参数由net.parameters()导出： . params = list(net.parameters()) print(len(params)) print(params[0].size()) . 10 torch.Size([6, 1, 3, 3]) . 我们测试一个随机的32x32输入。注意这个网络的输入大小是32x32。为了在MNIST数据集上使用这个网络，必需将数据的大小变换为32x32: . input = torch.randn(1,1,32,32) out = net(input) print(out) . tensor([[-0.0251, -0.0923, -0.0807, -0.0411, 0.1351, 0.1501, 0.0616, -0.0283, 0.1091, 0.1278]], grad_fn=&lt;AddmmBackward&gt;) . 清空所有参数的梯度缓存，使用随机梯度进行反向传播： . net.zero_grad() ??torch.nn.Module.zero_grad # 这里为何要用随机，不用ones呢 out.backward(torch.randn(1,10)) . Signature: torch.nn.Module.zero_grad(self) Source: def zero_grad(self): r&#34;&#34;&#34;Sets gradients of all model parameters to zero.&#34;&#34;&#34; for p in self.parameters(): if p.grad is not None: p.grad.detach_() p.grad.zero_() File: c: users henryalps anaconda3 envs pytorch lib site-packages torch nn modules module.py Type: function . *注意 torch.nn只支持mini-batch，这意味着torch.nn包只支持以mini-batch形式输入的sample，不支持单个sample。 . 比如nn.Conv2d接受的是一个4D Tensor: . 5969324360.png 如果你只有一个样本，需要用input.unsqueeze(0)添加一个假的batch维度。 * . 在继续之前，先回顾一下我们见过的所有类： 回顾 . * torch.Tensor - 是一个支持backwrd()形式的自动差分操作的多维数组。他也持有梯度值； . nn.Module 神经网络模块，方便打包模型参数以加载、导出或者迁移。 . | nn.Parameter 在配置为Module的属性时，会被自动注册为模型参数。 . | autograd.Function 每个Tensor操作创建至少一个Function节点，该节点与一个创建Tensor的方法相关联。 . | . 我们已经做的 . 定义一个神经网络 | 处理输入并反向传播 | . 待做的 . 计算loss | 更新网络权重 | . &#25439;&#22833;&#20989;&#25968; . 损失函数接受（输出，目标）格式输入，并计算出一个值，用于衡量输出与目标之间的偏离程度。 . nn包提供了几种不同的损失函数。nn.MSELoss计算了输入与目标之间的均方误差。 . 比如： . output = net(input) target = torch.randn(10) target = target.view(1, -1) criterion = nn.MSELoss() loss = criterion(output, target) print(loss) . tensor(0.9722, grad_fn=&lt;MseLossBackward&gt;) . 现在，如果你用.grad_fn去跟随loss的反向传播过程，你会看到一个这样的计算图： input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear -&gt; MSELoss -&gt; loss 所以当我们调用loss.backward()时，整个计算图对loss求梯度，图中设置require_grad=True的Tensor将把它们的.grad属性与梯度相加。 . 比如，我们回溯几步： . print(loss.grad_fn) print(loss.grad_fn.next_functions[0][0]) print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) . &lt;MseLossBackward object at 0x00000250CC0A7278&gt; &lt;AddmmBackward object at 0x00000250CC0A7198&gt; &lt;AccumulateGrad object at 0x00000250CC0A7278&gt; . &#21453;&#21521;&#20256;&#25773; . 为了反向传播误差，我们必须手动调用loss.backward()。调用之前需要清除已有的梯度值，否则会累加到已有的梯度值上。 . 现在我们需要调用loss.backward()，并分别在调用前和调用后查看convI的偏差值。 . net.zero_grad() print(&#39;conv1.bias.grad befor backward&#39;) print(net.conv1.bias.grad) loss.backward() print(&#39;conv1.bias.grad after backward&#39;) print(net.conv1.bias.grad) . conv1.bias.grad befor backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0108, -0.0118, 0.0027, -0.0026, 0.0037, 0.0074]) . 现在，我们知道了如何应用损失函数。 . 需要学习的只有一个： . 更新网络的权重。 | . &#26435;&#37325;&#26356;&#26032; . 最简单的权重更新规则是随机梯度下降（SGD），如下： weight = weight - learning_rate * gradient 我们可以用简单的python代码实现该功能： . learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.date * learning_rate) . 但是，在你使用网络时，你可能想用不同的更新规则如Adam、RMSProp等。为了支持这些更新规则，我们创建了一个轻量包torch.optim以实现这些方法。使用非常简单： . import torch.optim as optim # 创建优化器 optimizer = optim.SGD(net.parameters(), lr=0.01) # 在训练的过程中 optimizer.zero_grad() output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() . 注意梯度缓存必须手动用optimizer.zero_grad()方式清除，这是因为梯度是一个累加值 . &#35757;&#32451;&#19968;&#20010;&#20998;&#31867;&#22120; . 你已经看到如何定义神经网络，计算损失并且更新网络的权重，现在你可能在思考。 . &#25968;&#25454;&#22312;&#21738;&#37324;&#65311; . 通常，在你处理图像、文本、声音或影像数据时，你可以用标准的python包将数据读入一个numpy数组，此后你就可以将数组转为tensor： . 图像方面，Pillow或OpenCV都有用 | 声音方面，scipy或者librosa都有用 | 文本方面，原始的python、cython、NLTK或者SpaCy都有用 | . 特别的，对于视觉类任务，我们创建了一个名为torchvision的包，可以用于Imagenet，CIFAR10，MNIST等数据集的导入。 这使得我们得以避免重写一些数据载入的代码。 . 本教程中，我们将用 CIFAR 10数据集举例。该数据集包含10个类别，每个样本都是一个33232的多维数组： 9638222999.png . &#35757;&#32451;&#22270;&#29255;&#20998;&#31867;&#22120; . 我们将依次进行下列操作： . 1.读取和正则化CIFAR 10 训练和测试集 2.定义一个CNN 3.定义一个损失函数 4.在训练集上完成训练 5.使用测试集完成测试 . 1. &#35835;&#21462;&#19982;&#27491;&#21017;&#21270;CIFAR10&#25968;&#25454;&#38598; . 使用torchvision时，读取CIFAR10数据集非常简单： . import torch import torchvision import torchvision.transforms as transforms . torchvision的输出是[0,1]之间的PILImage格式图片。我们将它们转化为[-1,1]之间的数据。 如果你在windows上运行遇到BrokenPipeError，将torch.utils.data.DataLoader()的num_worker参数设置为0 . import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) trainset = torchvision.datasets.CIFAR10(root=&#39;../data&#39;, train=True,download=True,transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=&#39;../data&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = (&#39;plane&#39;,&#39;car&#39;,&#39;bird&#39;,&#39;cat&#39;,&#39;deer&#39;,&#39;dog&#39;,&#39;frog&#39;,&#39;horse&#39;,&#39;ship&#39;,&#39;truck&#39;) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data cifar-10-python.tar.gz . 100.0% . Extracting ../data cifar-10-python.tar.gz to ../data Files already downloaded and verified . 我们看几张训练集中的图片： . import matplotlib.pyplot as plt import numpy as np def imshow(img): img = img/2 + 0.5 npimg = img.numpy() plt.imshow(np.transpose(npimg, (1,2,0))) plt.show() dataiter = iter(trainloader) images, labels = dataiter.next() # 查看图片 imshow(torchvision.utils.make_grid(images)) # 打印类别 print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) . cat car car bird . 2.&#23450;&#20041;&#19968;&#20010;CNN . 改造之前的CNN使其支持3个通道的图片： . import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 输入为3通道，输出为6个channel，每个channel为5*5卷积获取 self.conv1 = nn.Conv2d(3,6,5) # ？ 之前用nn.functional.max_pool2d即可，现在换成nn.MaxPool2d了 self.pool = nn.MaxPool2d(2,2) self.conv2 = nn.Conv2d(6,16,5) # 尾部的全连接层 # 5*5卷积得到的输出变小了 self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def num_flat_features(self, x): size = x.size()[1:] # batch维不会被压平 num_features = 1 for s in size: num_features *= s return num_features def forward(self, x): x = self.pool(F.relu(self.conv1(x))) # 如果是用的方阵的话也可以只写行数或列数 x = self.pool(F.relu(self.conv2(x))) # 形状变换 x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() print(net) . Net( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) . 3.&#23450;&#20041;&#25439;&#22833;&#20989;&#25968;&#21644;&#20248;&#21270;&#22120; . 我们用一个分类器交叉熵做为损失函数，并用带动量的SGD作为权重更新方法： . import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) . 4.&#35757;&#32451;&#32593;&#32476; . 开始变得好玩了，我们只需要遍历我们的数据迭代器，将输入喂给网络并进行优化： . for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data # 数据是一个序列 optimizer.zero_grad() # 清空梯度缓存 # 前向传播 outputs = net(inputs) # 反向传播 loss = criterion(outputs, labels) loss.backward() # 更新权重 optimizer.step() # 打印统计参数 running_loss += loss.item() if i%2000 == 1999: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i+1, running_loss / 2000)) running_loss = 0.0 print(&#39;Finished Training&#39;) . [1, 2000] loss: 2.226 [1, 4000] loss: 1.888 [1, 6000] loss: 1.717 [1, 8000] loss: 1.610 [1, 10000] loss: 1.523 [1, 12000] loss: 1.481 Finished Training [2, 2000] loss: 1.399 [2, 4000] loss: 1.367 [2, 6000] loss: 1.338 [2, 8000] loss: 1.311 [2, 10000] loss: 1.288 [2, 12000] loss: 1.294 Finished Training . 最后保存我们训练好的模型： . PATH = &#39;../model/cifar_net.pth&#39; torch.save(net.state_dict(), PATH) . 5.&#27979;&#35797;&#32593;&#32476;&#22312;&#27979;&#35797;&#38598;&#19978;&#30340;&#25928;&#26524; . 我们在训练集上训练了两个epoch，现在检查下网络是否有学到什么东西。 . 我们通过预测网络对于测试集的输出，并将其与ground-truth相互对比，如果预测结果正确，则将结果加入正确预测列表之内。 . 首先，看下测试集中的一个minibatch： . dataiter = iter(testloader) images, labels = dataiter.next() # 打印图片 imshow(torchvision.utils.make_grid(images)) print(&#39;GroundTruth:&#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) . GroundTruth: cat ship ship plane . 之后，我们加载已经读取的模型： . net = Net() net.load_state_dict(torch.load(PATH)) . &lt;All keys matched successfully&gt; . 现在我们看看网络认为上述示例是什么类型： . outputs = net(images) . 输出的是10个类别的分数。某个类别的分数越高，网络就越是认为样本属于这个类别。因此我们获取具有最大分数的类别作为结果： . _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4))) . Predicted: frog ship ship plane . ？错了一个，和原始教程中不一样。 我们再看看网络在整个数据集上的表现： . correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100*correct / total)) . Accuracy of the network on the 10000 test images: 55 % . 看起来比随机猜测好很多（随机猜测有10%的概率猜中，准确率的期望为 10%）。网络学到了一些东西。 . 我们看看在哪些类别上网络表现好，哪些差： . class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: image, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print(&#39;Accuracy of %5s : %2d %%&#39; % (classes[i], 100 * class_correct[i] / class_total[i])) . Accuracy of plane : 0 % Accuracy of car : 26 % Accuracy of bird : 0 % Accuracy of cat : 24 % Accuracy of deer : 0 % Accuracy of dog : 25 % Accuracy of frog : 0 % Accuracy of horse : 25 % Accuracy of ship : 0 % Accuracy of truck : 0 % . 我们该如何在GPU上运行这些网络呢？ . &#22312;GPU&#19978;&#36816;&#34892; . 可以用和迁移Tensor一样的方法将网络迁移到GPU上。 首先设置设备为首个cuda设备，如果cuda可用的话： . device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(device) . cuda:0 . 如若机器上有CUDA设备，那么这些方法将递归地遍历所有模块，并将它们的参数和缓存转换为cuda上的张量： . net.to(device) . Net( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) . 同时，你也需要将每一步的输入和目标送个GPU: . inputs,labels = data[0].to(device), data[1].to(device) . 为什么GPU速度没有明显提升呢？因为网络太小了。 . 练习增加网络的宽度（首个nn.Conv2d的第二个参数与第二个nn.Conv2d的第一个参数），看看加速能达到多少。 . 目标完成： . 理解Tensor库和神经网络 | 训练一个小的神经网络用于分类图片 | .",
            "url": "https://henryalps.github.io/fastpages/jupyter/pytorch/2020/05/30/Getting-Pytorch-one-hour.html",
            "relUrl": "/jupyter/pytorch/2020/05/30/Getting-Pytorch-one-hour.html",
            "date": " • May 30, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "自动生成Jupyter笔记本文件",
            "content": "&#21407;&#22240; . 由于手动创建符合FastPages的笔记本文件比较麻烦（对文件名，格式都有要求），因此，使用代码简单生成一个脚手架文件。 . &#26041;&#27861; . ① 打开目录下的‘tools.ipynb’文件； . ② 修改标题、描述等配置信息； . ③ 运行后即可生成笔记本文件 . tips . 可以在_config.yml中排除tools.ipynb，避免它也生成一个页面。 .",
            "url": "https://henryalps.github.io/fastpages/jupyter/2020/05/24/Notebook-files-automatically-generated-Jupyter.html",
            "relUrl": "/jupyter/2020/05/24/Notebook-files-automatically-generated-Jupyter.html",
            "date": " • May 24, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "基本算法练习",
            "content": "&#24555;&#36895;&#25490;&#24207; . 基本思想 选择哨兵，将比它大的放到左边，小的放到右边。再对左右重复进行上述过程。 . def fast_sort(seq, start, end): if start &gt;= end: return seq # end选为哨兵 sequential_idx = end left_idx = start right_idx = end - 1 while left_idx &lt; right_idx: if seq[left_idx] &gt; seq[sequential_idx] and seq[right_idx] &lt; seq[sequential_idx]: tmp = seq[left_idx] seq[left_idx] = seq[right_idx] seq[right_idx] = tmp left_idx += 1 right_idx -= 1 elif seq[right_idx] &lt; seq[sequential_idx]: left_idx += 1 elif seq[left_idx] &gt; seq[sequential_idx]: right_idx -= 1 else: left_idx += 1 right_idx -= 1 lower_idx = min([left_idx, right_idx]) if seq[sequential_idx] &gt; seq[lower_idx]: tmp = seq[sequential_idx] seq[sequential_idx] = seq[lower_idx + 1] seq[lower_idx + 1] = tmp fast_sort(seq, start, lower_idx) fast_sort(seq, lower_idx + 2, end) else: tmp = seq[sequential_idx] seq[sequential_idx] = seq[lower_idx] seq[lower_idx] = tmp fast_sort(seq, start, lower_idx - 1) fast_sort(seq, lower_idx + 1, end) return seq if &#39;__main__&#39; == __name__: seq = [1,3,4,2,1] print(fast_sort(seq, 0, len(seq) - 1)) seq = [] print(fast_sort(seq, 0, len(seq) - 1)) seq = [2,1] print(fast_sort(seq, 0, len(seq) - 1)) seq = [2,1,1,1,1] print(fast_sort(seq, 0, len(seq) - 1)) . [1, 1, 2, 3, 4] [] [1, 2] [1, 1, 1, 1, 2] . &#34920;&#36798;&#24335;&#27714;&#20540; . 给定一个带括号和加号的表达式，对其进行求值。 . def eval(exp): symbol_stack = [] exp_stack = [] val_stack = [-1] for ch in exp: if ch == &#39;(&#39;: symbol_stack.append(ch) elif ch == &#39;)&#39;: exp = exp_stack.pop() right = val_stack.pop() left = val_stack.pop() if exp == &#39;+&#39;: val_stack.append(right + left) elif ch == &#39;+&#39;: exp_stack.append(ch) else: val_stack.append(int(ch)) while len(exp_stack) &gt; 0: right = val_stack.pop() left = val_stack.pop() if (exp_stack.pop() == &#39;+&#39;): val_stack.append(right + left) return val_stack.pop() if __name__ == &quot;__main__&quot;: print(eval(&#39;(1+2)+(4+5)+6&#39;)) . 18 .",
            "url": "https://henryalps.github.io/fastpages/python/jupyter/2020/05/16/python-code-snippets.html",
            "relUrl": "/python/jupyter/2020/05/16/python-code-snippets.html",
            "date": " • May 16, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "如何用python的for实现死循环",
            "content": "import logging logger = logging.getLogger(__name__) logger.setLevel(logging.WARNING) console = logging.StreamHandler() logger.addHandler(console) formatter = logging.Formatter(fmt=&#39;%(asctime)s %(message)s&#39;,datefmt=&#39;%Y-%m-%d,%H:%M:%S.%f&#39;) console.setFormatter(formatter) # 遍历一个数组时，操作这个数组不断在后边插入，同时删除已遍历的元素 inc_list = [0] for i in inc_list: logging.warning(&#39;looping...&#39;) del i inc_list.append(0) . WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-1-21798d70db2e&gt; in &lt;module&gt; 10 inc_list = [0] 11 for i in inc_list: &gt; 12 logging.warning(&#39;looping...&#39;) 13 del i 14 inc_list.append(0) ~ Anaconda3 envs tensorflow lib logging __init__.py in warning(msg, *args, **kwargs) 1885 if len(root.handlers) == 0: 1886 basicConfig() -&gt; 1887 root.warning(msg, *args, **kwargs) 1888 1889 def warn(msg, *args, **kwargs): ~ Anaconda3 envs tensorflow lib logging __init__.py in warning(self, msg, *args, **kwargs) 1318 &#34;&#34;&#34; 1319 if self.isEnabledFor(WARNING): -&gt; 1320 self._log(WARNING, msg, args, **kwargs) 1321 1322 def warn(self, msg, *args, **kwargs): ~ Anaconda3 envs tensorflow lib logging __init__.py in _log(self, level, msg, args, exc_info, extra, stack_info) 1442 record = self.makeRecord(self.name, level, fn, lno, msg, args, 1443 exc_info, func, extra, sinfo) -&gt; 1444 self.handle(record) 1445 1446 def handle(self, record): ~ Anaconda3 envs tensorflow lib logging __init__.py in handle(self, record) 1452 &#34;&#34;&#34; 1453 if (not self.disabled) and self.filter(record): -&gt; 1454 self.callHandlers(record) 1455 1456 def addHandler(self, hdlr): ~ Anaconda3 envs tensorflow lib logging __init__.py in callHandlers(self, record) 1514 found = found + 1 1515 if record.levelno &gt;= hdlr.level: -&gt; 1516 hdlr.handle(record) 1517 if not c.propagate: 1518 c = None #break out ~ Anaconda3 envs tensorflow lib logging __init__.py in handle(self, record) 863 self.acquire() 864 try: --&gt; 865 self.emit(record) 866 finally: 867 self.release() ~ Anaconda3 envs tensorflow lib logging __init__.py in emit(self, record) 994 msg = self.format(record) 995 stream = self.stream --&gt; 996 stream.write(msg) 997 stream.write(self.terminator) 998 self.flush() ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in write(self, string) 408 self.flush() 409 else: --&gt; 410 self._schedule_flush() 411 412 def writelines(self, sequence): ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in _schedule_flush(self) 332 def _schedule_in_thread(): 333 self._io_loop.call_later(self.flush_interval, self._flush) --&gt; 334 self.pub_thread.schedule(_schedule_in_thread) 335 336 def flush(self): ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in schedule(self, f) 203 self._events.append(f) 204 # wake event thread (message content is ignored) --&gt; 205 self._event_pipe.send(b&#39;&#39;) 206 else: 207 f() ~ Anaconda3 envs tensorflow lib site-packages zmq sugar socket.py in send(self, data, flags, copy, track, routing_id, group) 398 copy_threshold=self.copy_threshold) 399 data.group = group --&gt; 400 return super(Socket, self).send(data, flags=flags, copy=copy, track=track) 401 402 def send_multipart(self, msg_parts, flags=0, copy=True, track=False, **kwargs): zmq/backend/cython/socket.pyx in zmq.backend.cython.socket.Socket.send() zmq/backend/cython/socket.pyx in zmq.backend.cython.socket.Socket.send() zmq/backend/cython/socket.pyx in zmq.backend.cython.socket._send_copy() ~ Anaconda3 envs tensorflow lib site-packages zmq backend cython checkrc.pxd in zmq.backend.cython.checkrc._check_rc() KeyboardInterrupt: .",
            "url": "https://henryalps.github.io/fastpages/python/jupyter/2020/05/16/how-to-write-infinete-loop-with-python-for.html",
            "relUrl": "/python/jupyter/2020/05/16/how-to-write-infinete-loop-with-python-for.html",
            "date": " • May 16, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "图示各种Tensor操作",
            "content": "Tensor&#30340;&#24418;&#29366; . Tensor是什么？ | . 机器学习中的定义下，Tensor是数据的容器。我将其理解为每个元素大小都相等的N维数组。 但在严格的数学定义中，Tensor又不仅仅是数据的容器，Tensor具备几何意义，其中的每个元素实际上表示了某个基向量的权重。 . 为什么要用Tensor? | . 机器学习中，使用Tensor纯粹是需要定义这样一种数据类型--换个名字都可以。 根据某YouTude视频，由于Tensor表征了不同基向量之间的组合。这意味着即使空间发生变换（不涉及升降维），Tensor中存储的信息也不会发生改变，所以Tensor实际是对信息的一种最精简的表示（如果对空间进行变换，基向量互相垂直的关系是否会发生改变？） .",
            "url": "https://henryalps.github.io/fastpages/tensorflow/jupyter/2020/05/04/tensor-operation.html",
            "relUrl": "/tensorflow/jupyter/2020/05/04/tensor-operation.html",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "强推使用FastPages搭建博客",
            "content": "&#20160;&#20040;&#26159;FastPages . FASTAI出品的一个易用的博客框架，尤其突出的特性是对JupyterNoteBook的支持。 . &#22914;&#20309;&#23433;&#35013;FastPages . 非常简单。 . （1）通过这个链接生成一份fork； . （2）GitHub会在约30s后为你的fork开一个Pull Request； . （3）进入Pull Request，按要求首先创建一对 RSA 密钥对。你可以在本地用ssh-key-gen命令创建； . （4）配置RSA密钥对。注意private key命名必须是SSH_DEPLOY_KEY，不然后边部署时会报错； . （5）Merge这个Pull Request，30s后就可以见到你的博客了； . （5）如果Merge过程中出现错误，可以到Actions页面里边点击重试. . &#22914;&#20309;&#37197;&#32622;FastPages . FastPages安装完成后，初始页面看起来是这个样子的： . 8217404509.png 修改① - 在_config.yml中修改title字段 . 修改② - 在_pages中修改about.md . 修改③ - 在根目录下修改index.html . 修改④ - 在_config.yml中修改description字段 . 修改⑤ - 在_config.yml中修改social_links字段 . &#38382;&#39064; . (1)如果你遇到了类似这样的错误-- . jekyll_1 | Liquid Exception: Permission denied @ rb_sysopen - /data/.tweet-cache/ee341900d3bc668607abd8cba365fd1b.cache in /data/_posts/2020-01-14-test-markdown-post.md jekyll_1 | /usr/local/bundle/ruby/2.6.0/gems/jekyll-twitter-plugin-2.1.0/lib/jekyll-twitter-plugin.rb:41:in `initialize&#39;: Permission denied @ rb_sysopen - /data/.tweet-cache/ee341900d3bc668607abd8cba365fd1b.cache (Errno::EACCES) . 请在目录下执行以下命令： . mkdir .jekyll-cache _site .tweet-cache &amp;&amp; touch .jekyll-metadata . 如果仍有问题，则在docker-compose.yml中，jekyll -&gt; command节点下，加入以下语句： . chmod 777 * .tweet-cache . (2) 如果你发现笔记本中粘贴的图片无法展示 -- 请升级到最新版本的fastpages。 . (3) 如果你发现在粘贴图片后CI状态变为Fail -- . 请按照代码方式更新你的nb2post.py文件。 . (4) 如何用Jupyter Lab快速打开目录（windows） . Jupyter Lab默认打开的是用户目录，如何实现快速打开任意路径下的fastpages文件呢？建符号链接 -- . 复制fastpages的_notebooks路径 {dir} . | 用户目录下打开文件资源管理器，ctrl+L，输入cmd打开命令提示符 . | 输入mklink /J notebook {dir} . | jupyter lab启动后直接打开notebook文件夹即可 . | . (5) Jekyll build very slow - Jekyll Rendering Liquid非常缓慢 . 如果你在文章中包含了大量的base64编码图片，会造成Jekyll Rendering特别慢（超过1h） . 解决方案 ：预处理的时候将base64编码保存为图片，再链接到文章中即可。参考代码方式更新你的nb2post.py文件。 . &#24635;&#32467; . FastPages博客的配置和更新方式都和维护一般Git项目类似，对NoteBook的支持应该会催生一批数据科学家用户。 . PS:这篇文章同步发表于Gridea .",
            "url": "https://henryalps.github.io/fastpages/jupyter/2020/05/04/fastpages.html",
            "relUrl": "/jupyter/2020/05/04/fastpages.html",
            "date": " • May 4, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "關於",
          "content": "詩雲： 世間豈得桃源路，陶庵夢斷終不覓。 . Arxiv歎何其多，知乎亦苦難窮盡。 花落水走了無痕，千帆過罷空餘恨。 惟願心做金石意，要留新語在人間。 .",
          "url": "https://henryalps.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://henryalps.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}