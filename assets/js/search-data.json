{
  
    
        "post0": {
            "title": "create a new blog!",
            "content": "!pip install translation . ^C . from googletrans import Translator from datetime import datetime from functools import lru_cache title=&#39;自动生成Jupyter笔记本文件&#39; description=&#39;使用代码自动生成的Jupyter笔记本文件&#39; toc=&#39;true&#39; tags=&#39;,&#39;.join([&#39;jupyter&#39;]) branch=&#39;master&#39; badges=&#39;true&#39; comments=&#39;true&#39; date=datetime.today().strftime(&#39;%Y-%m-%d&#39;) @lru_cache(maxsize=10) def translate(text): return &#39;-&#39;.join(Translator().translate(text).text.split()) if len(title) &lt; 1: print(&#39;title not set!&#39;) exit() format_title = translate(title) print(format_title) import nbformat as nbf nb = nbf.v4.new_notebook() text = &quot;&quot;&quot; # {title} - toc: {toc} - branch: {branch} - badges: {badges} - comments: {comments} - categories: [{tags}] - description: {description} &quot;&quot;&quot;.format(title=title, toc=toc, branch=branch, badges=badges, comments=comments, tags=tags, description=description) print(text) nb[&#39;cells&#39;] = [nbf.v4.new_markdown_cell(text)] nbf.write(nb, &#39;{}-{}.ipynb&#39;.format(date,format_title)) . Notebook-files-automatically-generated-Jupyter # 自动生成Jupyter笔记本文件 - toc: true - branch: master - badges: true - comments: true - categories: [jupyter] - description: 使用代码自动生成的Jupyter笔记本文件 .",
            "url": "https://henryalps.github.io/fastpages/2020/05/30/tools.html",
            "relUrl": "/2020/05/30/tools.html",
            "date": " • May 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Pytorch一小时入门",
            "content": "更新记录： . 20/05/31(I) 完成前两节（30min）的内容 . 20/05/31(II) 完成后两节（30min）的内容 . 学习了DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ，将过程记录在此处。 . TK: add title . 1.理解PyTorch的Tensor库 | 2.Autograd自动求导的应用 | 3.构建神经网络 | 4.一个实际的例子 | . &#29702;&#35299;PyTorch&#30340;Tensor&#24211; . Tesnsor&#30340;&#23450;&#20041; . Tensors和NumPy的ndarray结构很像，区别是Tensor可以用于GPU计算。 . from __future__ import print_function import torch # check the GPU support dir(torch.cuda) . [&#39;BFloat16Storage&#39;, &#39;BFloat16Tensor&#39;, &#39;BoolStorage&#39;, &#39;BoolTensor&#39;, &#39;ByteStorage&#39;, &#39;ByteTensor&#39;, &#39;CharStorage&#39;, &#39;CharTensor&#39;, &#39;CudaError&#39;, &#39;DeferredCudaCallError&#39;, &#39;DoubleStorage&#39;, &#39;DoubleTensor&#39;, &#39;Event&#39;, &#39;FloatStorage&#39;, &#39;FloatTensor&#39;, &#39;HalfStorage&#39;, &#39;HalfTensor&#39;, &#39;IntStorage&#39;, &#39;IntTensor&#39;, &#39;LongStorage&#39;, &#39;LongTensor&#39;, &#39;PIPE&#39;, &#39;Popen&#39;, &#39;ShortStorage&#39;, &#39;ShortTensor&#39;, &#39;Stream&#39;, &#39;_CudaBase&#39;, &#39;_StorageBase&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;_after_fork&#39;, &#39;_check_capability&#39;, &#39;_check_driver&#39;, &#39;_cudart&#39;, &#39;_dummy_type&#39;, &#39;_free_mutex&#39;, &#39;_get_device_index&#39;, &#39;_host_allocator&#39;, &#39;_in_bad_fork&#39;, &#39;_initialized&#39;, &#39;_lazy_call&#39;, &#39;_lazy_init&#39;, &#39;_lazy_new&#39;, &#39;_load_cudart&#39;, &#39;_original_pid&#39;, &#39;_queued_calls&#39;, &#39;_register_after_fork&#39;, &#39;_sleep&#39;, &#39;_utils&#39;, &#39;check_error&#39;, &#39;comm&#39;, &#39;contextlib&#39;, &#39;ctypes&#39;, &#39;cudaStatus&#39;, &#39;cudart&#39;, &#39;current_blas_handle&#39;, &#39;current_device&#39;, &#39;current_stream&#39;, &#39;default_stream&#39;, &#39;device&#39;, &#39;device_count&#39;, &#39;device_of&#39;, &#39;empty_cache&#39;, &#39;find_cuda_windows_lib&#39;, &#39;get_device_capability&#39;, &#39;get_device_name&#39;, &#39;get_device_properties&#39;, &#39;get_rng_state&#39;, &#39;get_rng_state_all&#39;, &#39;init&#39;, &#39;initial_seed&#39;, &#39;ipc_collect&#39;, &#39;is_available&#39;, &#39;manual_seed&#39;, &#39;manual_seed_all&#39;, &#39;max_memory_allocated&#39;, &#39;max_memory_cached&#39;, &#39;memory_allocated&#39;, &#39;memory_cached&#39;, &#39;nccl&#39;, &#39;nvtx&#39;, &#39;os&#39;, &#39;platform&#39;, &#39;profiler&#39;, &#39;raise_from&#39;, &#39;random&#39;, &#39;reset_max_memory_allocated&#39;, &#39;reset_max_memory_cached&#39;, &#39;seed&#39;, &#39;seed_all&#39;, &#39;set_device&#39;, &#39;set_rng_state&#39;, &#39;set_rng_state_all&#39;, &#39;sparse&#39;, &#39;stream&#39;, &#39;streams&#39;, &#39;synchronize&#39;, &#39;sys&#39;, &#39;torch&#39;, &#39;traceback&#39;, &#39;warnings&#39;] . assert(torch.cuda.is_available()) . 创建一个5x3张量，不初始化 . x=torch.empty(5,3) print(x) . tensor([[ 8.4078e-45, 0.0000e+00, 2.6136e-28], [ 5.5772e-43, -1.3120e-30, 4.5915e-41], [ 0.0000e+00, 0.0000e+00, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 0.0000e+00], [-1.3120e-30, 4.5915e-41, 0.0000e+00]]) . ???这里的表现和页面不一样，预期应该是全0才对 . 创建一个随机初始化张量 . x=torch.rand(5,3) print(x) . tensor([[0.3783, 0.4491, 0.0897], [0.2913, 0.1618, 0.6047], [0.2112, 0.3987, 0.1202], [0.8236, 0.2970, 0.4896], [0.4792, 0.2471, 0.6751]]) . 创建一个填0的long型张量 . x=torch.zeros(5,3,dtype=torch.long) print(x) . tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) . 从数据中直接创建一个张量 . x=torch.tensor([5.5,3.0]) print(x) . tensor([5.5000, 3.0000]) . 根据一个已有张量创建张量 . # 创建一个类型变为double型的全1张量 x=x.new_ones(5,3,dtype=torch.double) print(x) x=torch.randn_like(x,dtype=torch.float) print(x) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.4722, -0.4380, -1.0941], [ 0.6054, 0.6555, -1.1304], [-1.1721, 1.3889, 0.3657], [-1.6273, -0.0502, 0.8097], [ 1.3560, 0.1341, 1.6279]]) . torch.size实际是一个tuple . print(x.size()) print(x.size()[0]) . torch.Size([5, 3]) 5 . Tensor&#25805;&#20316; . 加法之两种符号类型 . # 类型1- 直接用加号 x = torch.ones(5,3) y = torch.zeros(5,3) print(x + y) # 类型2- 使用函数add print(torch.add(x,y)) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . ？？？为何要用两种符号表示呢 . 加法之指定结果tensor . result = torch.empty(5,3) torch.add(x,y,out=result) print(result) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . 加法之原位相加 . y.add_(x) print(y) . tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . 注意到所有原位运算都是在函数名后边加一个下划线 . 使用类似numpy的范围写法取tensor的部分值 . # 打印x的第一列 print(x[:,1]) # 打印x的第一行 print(x[1,:]) . tensor([1., 1., 1., 1., 1.]) tensor([1., 1., 1.]) . 改变tensor的维度 . x = torch.randn(4,4) y = x.view(16) # 只指定每行的元素数量，就可以计算出变换后的形状 z = x.view(-1, 2) print(x,y,z) . tensor([[ 1.7866, 1.8163, -0.4897, 0.6796], [-1.1594, 1.8653, -0.4756, -0.8084], [ 0.5253, 1.8867, 1.2337, -0.1705], [ 0.6688, 0.0531, -0.9582, -0.4612]]) tensor([ 1.7866, 1.8163, -0.4897, 0.6796, -1.1594, 1.8653, -0.4756, -0.8084, 0.5253, 1.8867, 1.2337, -0.1705, 0.6688, 0.0531, -0.9582, -0.4612]) tensor([[ 1.7866, 1.8163], [-0.4897, 0.6796], [-1.1594, 1.8653], [-0.4756, -0.8084], [ 0.5253, 1.8867], [ 1.2337, -0.1705], [ 0.6688, 0.0531], [-0.9582, -0.4612]]) . tensor的操作还有很多，此处实际没有完全列举 . Numpy&#26725;&#25509; - &#22312;tensor&#19982;numpy&#25968;&#32452;&#20043;&#38388;&#20114;&#30456;&#36716;&#25442; . numpy数组和tensor共享内存：这意味着对任何一个变量的改变都将同步到另一个上。 . 转化tensor为一个ndarray . a=torch.ones(5) b=a.numpy() print(a,b) . tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.] . 对tensor的改变将会反映到ndarray上 . a.add_(a) print(b) . [2. 2. 2. 2. 2.] . 对ndarray的改变将会反映到tensor上 . b+=1 print(a) . tensor([3., 3., 3., 3., 3.]) . 将ndarray转换为tensor . import numpy as np a = np.ones(5) #注意此处的变量命名 b = torch.from_numpy(a) np.add(a,1,out=a) print(a) print(b) . [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) . GPU&#19978;&#30340;tensor . 使用to()方法将tensor迁移到其它设备 . device = torch.device(&quot;cuda&quot;) y = torch.ones_like(x, device=device) x = x.to(device) z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.int)) . tensor([[ 2.7866, 2.8163, 0.5103, 1.6796], [-0.1594, 2.8653, 0.5244, 0.1916], [ 1.5253, 2.8867, 2.2337, 0.8295], [ 1.6688, 1.0531, 0.0418, 0.5388]], device=&#39;cuda:0&#39;) tensor([[2, 2, 0, 1], [0, 2, 0, 0], [1, 2, 2, 0], [1, 1, 0, 0]], dtype=torch.int32) . Autograd&#33258;&#21160;&#27714;&#23548;&#30340;&#24212;&#29992; . pytorch中神经网络的核心模块就是autograd包，我们简单地了解一下这个包，其后就可以开始训练我们的第一个神经网络了。 . autograd包可以对所有的tensor操作进行自动差分（？？？如何自定义运算符）。它是一个define-by-run的框架，也就是你的反向传播是由代码运行方式所决定的，每一个操作都会有不同。 . 我们用更简单的方式和例子进行解释。 . tensor . torch.Tensor是这个包的核心。如果你将其属性.requires_grad设为True，它将追踪其上的所有操作。当你完成计算后，可以调用.backward()方法以自动计算所有导数。这个tensor的导数将由.grad参数所体现。 . 为了结束对一个tensor求导的操作，你可以用.detach方法将它从计算历史中移除，以避免之后它又被继续求导。 . 为了避免对tensor求导占用内存，你可以将代码块用with torch.no_grad()包裹起来。这对模型评估尤其有用，因为其中可能存在设置了require_grad=True的参数，但我们却不需要求导数。 . Function类是另外一个非常常用的类。 . Tensor和Function共同作用以构建一个无环图，该图对完整的计算历史进行编码。每个tensor都有一个.grad_fn属性，其中保存了创建这个tensor的Function对象。（用户自己创建的tensor则没有这个属性） . 如果你想计算导数，你可以调用tensor的.backward()方法。如果tensor是一个标量（即包含单个元素），你不需要为backward()指定任何参数。但如果它有多于一个元素，则你必需为它指定gradient参数，其形状与该tensor对应。 . 创建一个tensor并设定require_grad为True以追踪其上的计算： . x = torch.ones(2,2,requires_grad=True) print(x) . tensor([[1., 1.], [1., 1.]], requires_grad=True) . tensor运算 . y = x + 2 print(y) . tensor([[3., 3.], [3., 3.]], grad_fn=&lt;AddBackward0&gt;) . 更多的tensor运算 . z = y * y * 3 out = z.mean() print(z, out) . tensor([[27., 27.], [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;) . .requires_grad_()可用于替换一个已有tensor的require_grad标志位。输入标志位默认为False。 . a = torch.randn(2,2) a=((a*3)/(a-1)) print(a.requires_grad) print(a.grad_fn) a.requires_grad_(True) print(a.requires_grad) print(a.grad_fn) b=(a*a).sum() print(b.grad_fn) . False None True None &lt;SumBackward0 object at 0x00000240968298D0&gt; . 进行反向传播。由于out是一个标量，所以无需传入参数 . out.backward() print(x.grad) . tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) . 如果我们将out定义为$o$,那么我们将有$o= frac{1}{4} sum_{i}3(x_i+2)^2$,此时$ frac{ partial o}{ partial x_i}= frac{3}{2}(x_i+2)$,因此$ frac{ partial o}{ partial x_i} mid_{x_i=1}=4.5$ . 数学上来说，如果你有一个因自变量都为向量的函数$ vec{y}=f( vec{x})$,那么$ vec{y}$对$ vec{x}$的导数为一个雅可比矩阵： . $J= left( begin{array}{ccc} frac{ partial y_{1}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{1}}{ partial x_{n}} vdots &amp; ddots &amp; vdots frac{ partial y_{m}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{n}} end{array} right)$ . 一般地，torch.autograd是一个用于计算向量-雅可比行列式乘积的工具。也就是说，给定任何向量$v=(v_1 v_2 ... v_m)^T$，如果$v$刚好是标量函数$l=g( vec{y})$的导数，也就是说$v= left( frac{ partial l}{ partial y_{1}} cdots frac{ partial l}{ partial y_{m}} right)^{T}$，那么根据链式法则有向量与雅克比行列式之积为 $J^{T} cdot v= left( begin{array}{ccc} frac{ partial y_{1}}{ partial x_{1}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{1}} vdots &amp; ddots &amp; vdots frac{ partial y_{1}}{ partial x_{n}} &amp; cdots &amp; frac{ partial y_{m}}{ partial x_{n}} end{array} right) left( begin{array}{c} frac{ partial l}{ partial y_{1}} frac{ partial l}{ partial y_{m}} end{array} right)= left( begin{array}{c} frac{ partial l}{ partial x_{1}} frac{ partial l}{ partial x_{n}} end{array} right)$ . 向量与雅克比行列式之积的这种性质使得，将额外的导数引入输出不为常量的模型非常方便。 现在我们看一下向量-雅克比积的一个例子： . x = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm()&lt;1000: y=y*2 print(y) . tensor([-800.3267, 194.5804, 608.2095], grad_fn=&lt;MulBackward0&gt;) . 在这个例子中y不再是一个标量了。torch.autograd不能直接计算完整的雅克比行列式，但如果我们只想要向量-雅克比行列式之积的话，就简单将向量传入backward参数即可： . v = torch.tensor([0.1,1.0,0.0001], dtype=torch.float) y.backward(v) print(x.grad) . tensor([5.1200e+01, 5.1200e+02, 5.1200e-02]) . 关于上面这一段知乎链接讲的比较清楚，主要动机是不允许tensor对tensor求导，只允许scalar对tensor求导。 . 如果想对已经设置requires_grad=True的张量停止自动求导，有两种方式： . 1.使用with torch.no_grad()包裹 . 2.使用.detach()获取一个新的不需导数的张量 . print(x.requires_grad) print((x**2).requires_grad) with torch.no_grad(): print((x**2).requires_grad) print(x.requires_grad) y=x.detach() print(y.requires_grad) print(x.eq(y).all()) . True True False True False tensor(True) . &#31070;&#32463;&#32593;&#32476; . torch.nn用于构建神经网络。 . 现在你已经了解了autograd包，nn依赖autograd以定义模型并对其求差分。nn.Module的一个实例会包含网络层，以及一个forward(input)方法用于返回output。 . 如，看看下边这个定义用于对位图分类的网络： . TK: add title . 上图是一个简单的前向网络，它接收输入，依次喂给几层，最终得到输出。 一个典型的训练过程如下： . 定义有一些可训练参数的网络 | 输入一组数据 | 前向传播 | 计算损失函数值 | 反向传播获取梯度 | 更新网络权重，通常使用weight=weight-learning_rate*gradient | . &#23450;&#20041;&#32593;&#32476; . 以下代码用于定义网络： . import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 输入只有一个灰度channel，输出为6个channel，每个channel为3*3卷积获取 self.conv1 = nn.Conv2d(1,6,3) self.conv2 = nn.Conv2d(6,16,3) # 尾部的全连接层 # 3*3卷积得到的输出是6*6 self.fc1 = nn.Linear(16*6*6, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def num_flat_features(self, x): size = x.size()[1:] # batch维不会被压平 num_features = 1 for s in size: num_features *= s return num_features def forward(self, x): # 做最大池化以下采样 x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) # 如果是用的方阵的话也可以只写行数或列数 x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 形状变换 x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() print(net) . Net( (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) (fc1): Linear(in_features=576, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) . 你必需定义forward方法。backward方法会在指定autograd时自动计算得到。forard方法中可以用任意tensor操作。 . 网络可学习的参数由net.parameters()导出： . params = list(net.parameters()) print(len(params)) print(params[0].size()) . 10 torch.Size([6, 1, 3, 3]) . 我们测试一个随机的32x32输入。注意这个网络的输入大小是32x32。为了在MNIST数据集上使用这个网络，必需将数据的大小变换为32x32: . input = torch.randn(1,1,32,32) out = net(input) print(out) . tensor([[-0.0251, -0.0923, -0.0807, -0.0411, 0.1351, 0.1501, 0.0616, -0.0283, 0.1091, 0.1278]], grad_fn=&lt;AddmmBackward&gt;) . 清空所有参数的梯度缓存，使用随机梯度进行反向传播： . net.zero_grad() ??torch.nn.Module.zero_grad # 这里为何要用随机，不用ones呢 out.backward(torch.randn(1,10)) . Signature: torch.nn.Module.zero_grad(self) Source: def zero_grad(self): r&#34;&#34;&#34;Sets gradients of all model parameters to zero.&#34;&#34;&#34; for p in self.parameters(): if p.grad is not None: p.grad.detach_() p.grad.zero_() File: c: users henryalps anaconda3 envs pytorch lib site-packages torch nn modules module.py Type: function . *注意 torch.nn只支持mini-batch，这意味着torch.nn包只支持以mini-batch形式输入的sample，不支持单个sample。 . 比如nn.Conv2d接受的是一个4D Tensor: . TK: add title 如果你只有一个样本，需要用input.unsqueeze(0)添加一个假的batch维度。 * . 在继续之前，先回顾一下我们见过的所有类： 回顾 . * torch.Tensor - 是一个支持backwrd()形式的自动差分操作的多维数组。他也持有梯度值； . nn.Module 神经网络模块，方便打包模型参数以加载、导出或者迁移。 . | nn.Parameter 在配置为Module的属性时，会被自动注册为模型参数。 . | autograd.Function 每个Tensor操作创建至少一个Function节点，该节点与一个创建Tensor的方法相关联。 . | . 我们已经做的 . 定义一个神经网络 | 处理输入并反向传播 | . 待做的 . 计算loss | 更新网络权重 | . &#25439;&#22833;&#20989;&#25968; . 损失函数接受（输出，目标）格式输入，并计算出一个值，用于衡量输出与目标之间的偏离程度。 . nn包提供了几种不同的损失函数。nn.MSELoss计算了输入与目标之间的均方误差。 . 比如： . output = net(input) target = torch.randn(10) target = target.view(1, -1) criterion = nn.MSELoss() loss = criterion(output, target) print(loss) . tensor(0.9722, grad_fn=&lt;MseLossBackward&gt;) . 现在，如果你用.grad_fn去跟随loss的反向传播过程，你会看到一个这样的计算图： input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear -&gt; MSELoss -&gt; loss 所以当我们调用loss.backward()时，整个计算图对loss求梯度，图中设置require_grad=True的Tensor将把它们的.grad属性与梯度相加。 . 比如，我们回溯几步： . print(loss.grad_fn) print(loss.grad_fn.next_functions[0][0]) print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) . &lt;MseLossBackward object at 0x00000250CC0A7278&gt; &lt;AddmmBackward object at 0x00000250CC0A7198&gt; &lt;AccumulateGrad object at 0x00000250CC0A7278&gt; . &#21453;&#21521;&#20256;&#25773; . 为了反向传播误差，我们必须手动调用loss.backward()。调用之前需要清除已有的梯度值，否则会累加到已有的梯度值上。 . 现在我们需要调用loss.backward()，并分别在调用前和调用后查看convI的偏差值。 . net.zero_grad() print(&#39;conv1.bias.grad befor backward&#39;) print(net.conv1.bias.grad) loss.backward() print(&#39;conv1.bias.grad after backward&#39;) print(net.conv1.bias.grad) . conv1.bias.grad befor backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0108, -0.0118, 0.0027, -0.0026, 0.0037, 0.0074]) . 现在，我们知道了如何应用损失函数。 . 需要学习的只有一个： . 更新网络的权重。 | . &#26435;&#37325;&#26356;&#26032; . 最简单的权重更新规则是随机梯度下降（SGD），如下： weight = weight - learning_rate * gradient 我们可以用简单的python代码实现该功能： . learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.date * learning_rate) . 但是，在你使用网络时，你可能想用不同的更新规则如Adam、RMSProp等。为了支持这些更新规则，我们创建了一个轻量包torch.optim以实现这些方法。使用非常简单： . import torch.optim as optim # 创建优化器 optimizer = optim.SGD(net.parameters(), lr=0.01) # 在训练的过程中 optimizer.zero_grad() output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() . 注意梯度缓存必须手动用optimizer.zero_grad()方式清除，这是因为梯度是一个累加值 . &#35757;&#32451;&#19968;&#20010;&#20998;&#31867;&#22120; . 你已经看到如何定义神经网络，计算损失并且更新网络的权重，现在你可能在思考。 . &#25968;&#25454;&#22312;&#21738;&#37324;&#65311; . 通常，在你处理图像、文本、声音或影像数据时，你可以用标准的python包将数据读入一个numpy数组，此后你就可以将数组转为tensor： . 图像方面，Pillow或OpenCV都有用 | 声音方面，scipy或者librosa都有用 | 文本方面，原始的python、cython、NLTK或者SpaCy都有用 | . 特别的，对于视觉类任务，我们创建了一个名为torchvision的包，可以用于Imagenet，CIFAR10，MNIST等数据集的导入。 这使得我们得以避免重写一些数据载入的代码。 . 本教程中，我们将用 CIFAR 10数据集举例。该数据集包含10个类别，每个样本都是一个33232的多维数组： TK: add title . &#35757;&#32451;&#22270;&#29255;&#20998;&#31867;&#22120; . 我们将依次进行下列操作： . 1.读取和正则化CIFAR 10 训练和测试集 2.定义一个CNN 3.定义一个损失函数 4.在训练集上完成训练 5.使用测试集完成测试 . 1. &#35835;&#21462;&#19982;&#27491;&#21017;&#21270;CIFAR10&#25968;&#25454;&#38598; . 使用torchvision时，读取CIFAR10数据集非常简单： . import torch import torchvision import torchvision.transforms as transforms . torchvision的输出是[0,1]之间的PILImage格式图片。我们将它们转化为[-1,1]之间的数据。 如果你在windows上运行遇到BrokenPipeError，将torch.utils.data.DataLoader()的num_worker参数设置为0 . import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) trainset = torchvision.datasets.CIFAR10(root=&#39;../data&#39;, train=True,download=True,transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=&#39;../data&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = (&#39;plane&#39;,&#39;car&#39;,&#39;bird&#39;,&#39;cat&#39;,&#39;deer&#39;,&#39;dog&#39;,&#39;frog&#39;,&#39;horse&#39;,&#39;ship&#39;,&#39;truck&#39;) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data cifar-10-python.tar.gz . 100.0% . Extracting ../data cifar-10-python.tar.gz to ../data Files already downloaded and verified . 我们看几张训练集中的图片： . import matplotlib.pyplot as plt import numpy as np def imshow(img): img = img/2 + 0.5 npimg = img.numpy() plt.imshow(np.transpose(npimg, (1,2,0))) plt.show() dataiter = iter(trainloader) images, labels = dataiter.next() # 查看图片 imshow(torchvision.utils.make_grid(images)) # 打印类别 print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) . cat car car bird . 2.&#23450;&#20041;&#19968;&#20010;CNN . 改造之前的CNN使其支持3个通道的图片： . import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 输入为3通道，输出为6个channel，每个channel为5*5卷积获取 self.conv1 = nn.Conv2d(3,6,5) # ？ 之前用nn.functional.max_pool2d即可，现在换成nn.MaxPool2d了 self.pool = nn.MaxPool2d(2,2) self.conv2 = nn.Conv2d(6,16,5) # 尾部的全连接层 # 5*5卷积得到的输出变小了 self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def num_flat_features(self, x): size = x.size()[1:] # batch维不会被压平 num_features = 1 for s in size: num_features *= s return num_features def forward(self, x): x = self.pool(F.relu(self.conv1(x))) # 如果是用的方阵的话也可以只写行数或列数 x = self.pool(F.relu(self.conv2(x))) # 形状变换 x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() print(net) . Net( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) . 3.&#23450;&#20041;&#25439;&#22833;&#20989;&#25968;&#21644;&#20248;&#21270;&#22120; . 我们用一个分类器交叉熵做为损失函数，并用带动量的SGD作为权重更新方法： . import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) . 4.&#35757;&#32451;&#32593;&#32476; . 开始变得好玩了，我们只需要遍历我们的数据迭代器，将输入喂给网络并进行优化： . for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data # 数据是一个序列 optimizer.zero_grad() # 清空梯度缓存 # 前向传播 outputs = net(inputs) # 反向传播 loss = criterion(outputs, labels) loss.backward() # 更新权重 optimizer.step() # 打印统计参数 running_loss += loss.item() if i%2000 == 1999: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i+1, running_loss / 2000)) running_loss = 0.0 print(&#39;Finished Training&#39;) . [1, 2000] loss: 2.226 [1, 4000] loss: 1.888 [1, 6000] loss: 1.717 [1, 8000] loss: 1.610 [1, 10000] loss: 1.523 [1, 12000] loss: 1.481 Finished Training [2, 2000] loss: 1.399 [2, 4000] loss: 1.367 [2, 6000] loss: 1.338 [2, 8000] loss: 1.311 [2, 10000] loss: 1.288 [2, 12000] loss: 1.294 Finished Training . 最后保存我们训练好的模型： . PATH = &#39;../model/cifar_net.pth&#39; torch.save(net.state_dict(), PATH) . 5.&#27979;&#35797;&#32593;&#32476;&#22312;&#27979;&#35797;&#38598;&#19978;&#30340;&#25928;&#26524; . 我们在训练集上训练了两个epoch，现在检查下网络是否有学到什么东西。 . 我们通过预测网络对于测试集的输出，并将其与ground-truth相互对比，如果预测结果正确，则将结果加入正确预测列表之内。 . 首先，看下测试集中的一个minibatch： . dataiter = iter(testloader) images, labels = dataiter.next() # 打印图片 imshow(torchvision.utils.make_grid(images)) print(&#39;GroundTruth:&#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) . GroundTruth: cat ship ship plane . 之后，我们加载已经读取的模型： . net = Net() net.load_state_dict(torch.load(PATH)) . &lt;All keys matched successfully&gt; . 现在我们看看网络认为上述示例是什么类型： . outputs = net(images) . 输出的是10个类别的分数。某个类别的分数越高，网络就越是认为样本属于这个类别。因此我们获取具有最大分数的类别作为结果： . _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4))) . Predicted: frog ship ship plane . ？错了一个，和原始教程中不一样。 我们再看看网络在整个数据集上的表现： . correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100*correct / total)) . Accuracy of the network on the 10000 test images: 55 % . 看起来比随机猜测好很多（随机猜测有10%的概率猜中，准确率的期望为 10%）。网络学到了一些东西。 . 我们看看在哪些类别上网络表现好，哪些差： . class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: image, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print(&#39;Accuracy of %5s : %2d %%&#39; % (classes[i], 100 * class_correct[i] / class_total[i])) . Accuracy of plane : 0 % Accuracy of car : 26 % Accuracy of bird : 0 % Accuracy of cat : 24 % Accuracy of deer : 0 % Accuracy of dog : 25 % Accuracy of frog : 0 % Accuracy of horse : 25 % Accuracy of ship : 0 % Accuracy of truck : 0 % . 我们该如何在GPU上运行这些网络呢？ . &#22312;GPU&#19978;&#36816;&#34892; . 可以用和迁移Tensor一样的方法将网络迁移到GPU上。 首先设置设备为首个cuda设备，如果cuda可用的话： . device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(device) . cuda:0 . 如若机器上有CUDA设备，那么这些方法将递归地遍历所有模块，并将它们的参数和缓存转换为cuda上的张量： . net.to(device) . Net( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) . 同时，你也需要将每一步的输入和目标送个GPU: . inputs,labels = data[0].to(device), data[1].to(device) . 为什么GPU速度没有明显提升呢？因为网络太小了。 . 练习增加网络的宽度（首个nn.Conv2d的第二个参数与第二个nn.Conv2d的第一个参数），看看加速能达到多少。 . 目标完成： . 理解Tensor库和神经网络 | 训练一个小的神经网络用于分类图片 | .",
            "url": "https://henryalps.github.io/fastpages/jupyter/pytorch/2020/05/30/Getting-Pytorch-one-hour.html",
            "relUrl": "/jupyter/pytorch/2020/05/30/Getting-Pytorch-one-hour.html",
            "date": " • May 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "自动生成Jupyter笔记本文件",
            "content": "&#21407;&#22240; . 由于手动创建符合FastPages的笔记本文件比较麻烦（对文件名，格式都有要求），因此，使用代码简单生成一个脚手架文件。 . &#26041;&#27861; . ① 打开目录下的‘tools.ipynb’文件； . ② 修改标题、描述等配置信息； . ③ 运行后即可生成笔记本文件 . tips . 可以在_config.yml中排除tools.ipynb，避免它也生成一个页面。 .",
            "url": "https://henryalps.github.io/fastpages/jupyter/2020/05/24/Notebook-files-automatically-generated-Jupyter.html",
            "relUrl": "/jupyter/2020/05/24/Notebook-files-automatically-generated-Jupyter.html",
            "date": " • May 24, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "基本算法练习",
            "content": "&#24555;&#36895;&#25490;&#24207; . 基本思想 选择哨兵，将比它大的放到左边，小的放到右边。再对左右重复进行上述过程。 . def fast_sort(seq, start, end): if start &gt;= end: return seq # end选为哨兵 sequential_idx = end left_idx = start right_idx = end - 1 while left_idx &lt; right_idx: if seq[left_idx] &gt; seq[sequential_idx] and seq[right_idx] &lt; seq[sequential_idx]: tmp = seq[left_idx] seq[left_idx] = seq[right_idx] seq[right_idx] = tmp left_idx += 1 right_idx -= 1 elif seq[right_idx] &lt; seq[sequential_idx]: left_idx += 1 elif seq[left_idx] &gt; seq[sequential_idx]: right_idx -= 1 else: left_idx += 1 right_idx -= 1 lower_idx = min([left_idx, right_idx]) if seq[sequential_idx] &gt; seq[lower_idx]: tmp = seq[sequential_idx] seq[sequential_idx] = seq[lower_idx + 1] seq[lower_idx + 1] = tmp fast_sort(seq, start, lower_idx) fast_sort(seq, lower_idx + 2, end) else: tmp = seq[sequential_idx] seq[sequential_idx] = seq[lower_idx] seq[lower_idx] = tmp fast_sort(seq, start, lower_idx - 1) fast_sort(seq, lower_idx + 1, end) return seq if &#39;__main__&#39; == __name__: seq = [1,3,4,2,1] print(fast_sort(seq, 0, len(seq) - 1)) seq = [] print(fast_sort(seq, 0, len(seq) - 1)) seq = [2,1] print(fast_sort(seq, 0, len(seq) - 1)) seq = [2,1,1,1,1] print(fast_sort(seq, 0, len(seq) - 1)) . [1, 1, 2, 3, 4] [] [1, 2] [1, 1, 1, 1, 2] . &#34920;&#36798;&#24335;&#27714;&#20540; . 给定一个带括号和加号的表达式，对其进行求值。 . def eval(exp): symbol_stack = [] exp_stack = [] val_stack = [-1] for ch in exp: if ch == &#39;(&#39;: symbol_stack.append(ch) elif ch == &#39;)&#39;: exp = exp_stack.pop() right = val_stack.pop() left = val_stack.pop() if exp == &#39;+&#39;: val_stack.append(right + left) elif ch == &#39;+&#39;: exp_stack.append(ch) else: val_stack.append(int(ch)) while len(exp_stack) &gt; 0: right = val_stack.pop() left = val_stack.pop() if (exp_stack.pop() == &#39;+&#39;): val_stack.append(right + left) return val_stack.pop() if __name__ == &quot;__main__&quot;: print(eval(&#39;(1+2)+(4+5)+6&#39;)) . 18 .",
            "url": "https://henryalps.github.io/fastpages/python/jupyter/2020/05/16/python-code-snippets.html",
            "relUrl": "/python/jupyter/2020/05/16/python-code-snippets.html",
            "date": " • May 16, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "如何用python的for实现死循环",
            "content": "import logging logger = logging.getLogger(__name__) logger.setLevel(logging.WARNING) console = logging.StreamHandler() logger.addHandler(console) formatter = logging.Formatter(fmt=&#39;%(asctime)s %(message)s&#39;,datefmt=&#39;%Y-%m-%d,%H:%M:%S.%f&#39;) console.setFormatter(formatter) # 遍历一个数组时，操作这个数组不断在后边插入，同时删除已遍历的元素 inc_list = [0] for i in inc_list: logging.warning(&#39;looping...&#39;) del i inc_list.append(0) . WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... WARNING:root:looping... . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-1-21798d70db2e&gt; in &lt;module&gt; 10 inc_list = [0] 11 for i in inc_list: &gt; 12 logging.warning(&#39;looping...&#39;) 13 del i 14 inc_list.append(0) ~ Anaconda3 envs tensorflow lib logging __init__.py in warning(msg, *args, **kwargs) 1885 if len(root.handlers) == 0: 1886 basicConfig() -&gt; 1887 root.warning(msg, *args, **kwargs) 1888 1889 def warn(msg, *args, **kwargs): ~ Anaconda3 envs tensorflow lib logging __init__.py in warning(self, msg, *args, **kwargs) 1318 &#34;&#34;&#34; 1319 if self.isEnabledFor(WARNING): -&gt; 1320 self._log(WARNING, msg, args, **kwargs) 1321 1322 def warn(self, msg, *args, **kwargs): ~ Anaconda3 envs tensorflow lib logging __init__.py in _log(self, level, msg, args, exc_info, extra, stack_info) 1442 record = self.makeRecord(self.name, level, fn, lno, msg, args, 1443 exc_info, func, extra, sinfo) -&gt; 1444 self.handle(record) 1445 1446 def handle(self, record): ~ Anaconda3 envs tensorflow lib logging __init__.py in handle(self, record) 1452 &#34;&#34;&#34; 1453 if (not self.disabled) and self.filter(record): -&gt; 1454 self.callHandlers(record) 1455 1456 def addHandler(self, hdlr): ~ Anaconda3 envs tensorflow lib logging __init__.py in callHandlers(self, record) 1514 found = found + 1 1515 if record.levelno &gt;= hdlr.level: -&gt; 1516 hdlr.handle(record) 1517 if not c.propagate: 1518 c = None #break out ~ Anaconda3 envs tensorflow lib logging __init__.py in handle(self, record) 863 self.acquire() 864 try: --&gt; 865 self.emit(record) 866 finally: 867 self.release() ~ Anaconda3 envs tensorflow lib logging __init__.py in emit(self, record) 994 msg = self.format(record) 995 stream = self.stream --&gt; 996 stream.write(msg) 997 stream.write(self.terminator) 998 self.flush() ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in write(self, string) 408 self.flush() 409 else: --&gt; 410 self._schedule_flush() 411 412 def writelines(self, sequence): ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in _schedule_flush(self) 332 def _schedule_in_thread(): 333 self._io_loop.call_later(self.flush_interval, self._flush) --&gt; 334 self.pub_thread.schedule(_schedule_in_thread) 335 336 def flush(self): ~ Anaconda3 envs tensorflow lib site-packages ipykernel iostream.py in schedule(self, f) 203 self._events.append(f) 204 # wake event thread (message content is ignored) --&gt; 205 self._event_pipe.send(b&#39;&#39;) 206 else: 207 f() ~ Anaconda3 envs tensorflow lib site-packages zmq sugar socket.py in send(self, data, flags, copy, track, routing_id, group) 398 copy_threshold=self.copy_threshold) 399 data.group = group --&gt; 400 return super(Socket, self).send(data, flags=flags, copy=copy, track=track) 401 402 def send_multipart(self, msg_parts, flags=0, copy=True, track=False, **kwargs): zmq/backend/cython/socket.pyx in zmq.backend.cython.socket.Socket.send() zmq/backend/cython/socket.pyx in zmq.backend.cython.socket.Socket.send() zmq/backend/cython/socket.pyx in zmq.backend.cython.socket._send_copy() ~ Anaconda3 envs tensorflow lib site-packages zmq backend cython checkrc.pxd in zmq.backend.cython.checkrc._check_rc() KeyboardInterrupt: .",
            "url": "https://henryalps.github.io/fastpages/python/jupyter/2020/05/16/how-to-write-infinete-loop-with-python-for.html",
            "relUrl": "/python/jupyter/2020/05/16/how-to-write-infinete-loop-with-python-for.html",
            "date": " • May 16, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "图示各种Tensor操作",
            "content": "Tensor&#30340;&#24418;&#29366; . Tensor是什么？ | . 机器学习中的定义下，Tensor是数据的容器。我将其理解为每个元素大小都相等的N维数组。 但在严格的数学定义中，Tensor又不仅仅是数据的容器，Tensor具备几何意义，其中的每个元素实际上表示了某个基向量的权重。 . 为什么要用Tensor? | . 机器学习中，使用Tensor纯粹是需要定义这样一种数据类型--换个名字都可以。 根据某YouTude视频，由于Tensor表征了不同基向量之间的组合。这意味着即使空间发生变换（不涉及升降维），Tensor中存储的信息也不会发生改变，所以Tensor实际是对信息的一种最精简的表示（如果对空间进行变换，基向量互相垂直的关系是否会发生改变？） .",
            "url": "https://henryalps.github.io/fastpages/tensorflow/jupyter/2020/05/04/tensor-operation.html",
            "relUrl": "/tensorflow/jupyter/2020/05/04/tensor-operation.html",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "强推使用FastPages搭建博客",
            "content": "&#20160;&#20040;&#26159;FastPages . FASTAI出品的一个易用的博客框架，尤其突出的特性是对JupyterNoteBook的支持。 . &#22914;&#20309;&#23433;&#35013;FastPages . 非常简单。 . （1）通过这个链接生成一份fork； . （2）GitHub会在约30s后为你的fork开一个Pull Request； . （3）进入Pull Request，按要求首先创建一对 RSA 密钥对。你可以在本地用ssh-key-gen命令创建； . （4）配置RSA密钥对。注意private key命名必须是SSH_DEPLOY_KEY，不然后边部署时会报错； . （5）Merge这个Pull Request，30s后就可以见到你的博客了； . （5）如果Merge过程中出现错误，可以到Actions页面里边点击重试. . &#22914;&#20309;&#37197;&#32622;FastPages . FastPages安装完成后，初始页面看起来是这个样子的： . TK: add title 修改① - 在_config.yml中修改title字段 . 修改② - 在_pages中修改about.md . 修改③ - 在根目录下修改index.html . 修改④ - 在_config.yml中修改description字段 . 修改⑤ - 在_config.yml中修改social_links字段 . &#38382;&#39064; . (1)如果你遇到了类似这样的错误-- . jekyll_1 | Liquid Exception: Permission denied @ rb_sysopen - /data/.tweet-cache/ee341900d3bc668607abd8cba365fd1b.cache in /data/_posts/2020-01-14-test-markdown-post.md jekyll_1 | /usr/local/bundle/ruby/2.6.0/gems/jekyll-twitter-plugin-2.1.0/lib/jekyll-twitter-plugin.rb:41:in `initialize&#39;: Permission denied @ rb_sysopen - /data/.tweet-cache/ee341900d3bc668607abd8cba365fd1b.cache (Errno::EACCES) . 请在目录下执行以下命令： . mkdir .jekyll-cache _site .tweet-cache &amp;&amp; touch .jekyll-metadata . 如果仍有问题，则在docker-compose.yml中，jekyll -&gt; command节点下，加入以下语句： . chmod 777 * .tweet-cache . (2) 如果你发现笔记本中粘贴的图片无法展示 -- 请升级到最新版本的fastpages。 . (3) 如果你发现在粘贴图片后CI状态变为Fail -- . 请按照代码方式更新你的nb2post.py文件。 . (4) 如何用Jupyter Lab快速打开目录（windows） . Jupyter Lab默认打开的是用户目录，如何实现快速打开任意路径下的fastpages文件呢？建符号链接 -- . 复制fastpages的_notebooks路径 {dir} . | 用户目录下打开文件资源管理器，ctrl+L，输入cmd打开命令提示符 . | 输入mklink notebook {dir} . | jupyter lab启动后直接打开notebook文件夹即可 . | . &#24635;&#32467; . FastPages博客的配置和更新方式都和维护一般Git项目类似，对NoteBook的支持应该会催生一批数据科学家用户。 . PS:这篇文章同步发表于Gridea .",
            "url": "https://henryalps.github.io/fastpages/jupyter/2020/05/04/fastpages.html",
            "relUrl": "/jupyter/2020/05/04/fastpages.html",
            "date": " • May 4, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "關於",
          "content": "詩雲： 世間豈得桃源路，陶庵夢斷終不覓。 . Arxiv歎何其多，知乎亦苦難窮盡。 花落水走了無痕，千帆過罷空餘恨。 惟願心做金石意，要留新語在人間。 .",
          "url": "https://henryalps.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://henryalps.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}